{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000c9d7d",
   "metadata": {},
   "source": [
    "# Part B: Creating and exporting the input files \n",
    "\n",
    "## Introduction\n",
    "This notebook contains _all code_ that has been used to create, preprocess and export the _input data_ to be used for the modelling performed for the paper \"Can more detailed geological maps improve streamflow prediction in ungauged basins?\" paper by do Nascimento et al. (in review). To be able to run this notebook, please ensure that you have downloaded the acompanying data of the paper. All links can be found in the data section of the paper.\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109eb222",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "**Files**\n",
    "\n",
    "- estreams_gauging_stations.csv https://doi.org/10.5281/zenodo.14778580 (Last access: 11 February 2025)\n",
    "- estreams_geology_moselle_regional_attributes.csv https://doi.org/10.5281/zenodo.14778580 (Last access: 15 February 2025)\n",
    "- estreams_attributes_filtered_quality_geology_v01.csv https://github.com/thiagovmdon/LSH-quality_geology (Last access: 11 February 2025)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f276e00",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from utils.functions import find_max_unique_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d0aad",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to where the EStreams dataset is stored\n",
    "# Windows\n",
    "path_estreams = r'C:\\Users\\nascimth\\Documents\\data\\EStreams'\n",
    "\n",
    "## Mac\n",
    "#path_estreams = r'/Users/thiagomedeirosdonascimento/Downloads/Python 2/Scripts/estreams_part_b/data/EStreams'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf6f92",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64ca750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the gauges network metadata (from EStreams):\n",
    "network_estreams = pd.read_csv(path_estreams+'/streamflow_gauges/estreams_gauging_stations.csv', encoding='utf-8')\n",
    "network_estreams.set_index(\"basin_id\", inplace = True)\n",
    "\n",
    "# Attributes already filtered from EStreams previously in do Nascimento et al. (2025a):\n",
    "estreams_attributes = pd.read_csv('../data/estreams_attributes_filtered_quality_geology_v01.csv', encoding='utf-8')\n",
    "estreams_attributes.set_index(\"basin_id\", inplace = True)\n",
    "\n",
    "# Geological attributes (regional scale). Same ones provided in do Nascimento et al. (2025a):\n",
    "geology_regional_31_classes_moselle = pd.read_csv(\"../data/estreams_geology_moselle_regional_attributes.csv\", encoding='utf-8')\n",
    "geology_regional_31_classes_moselle.set_index(\"basin_id\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fd97d",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341e89d",
   "metadata": {},
   "source": [
    "### Network data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b166718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some adjusts in the data\n",
    "# Convert 'date_column' and 'time_column' to datetime\n",
    "network_estreams['start_date'] = pd.to_datetime(network_estreams['start_date'])\n",
    "network_estreams['end_date'] = pd.to_datetime(network_estreams['end_date'])\n",
    "\n",
    "# Convert to list both the nested_catchments and the duplicated_suspect columns\n",
    "network_estreams['nested_catchments'] = network_estreams['nested_catchments'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "\n",
    "# Remove the brackets and handle NaN values\n",
    "network_estreams['duplicated_suspect'] = network_estreams['duplicated_suspect'].apply(\n",
    "    lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \") if isinstance(x, str) else x)\n",
    "\n",
    "nested_catchments = pd.DataFrame(network_estreams['nested_catchments'])\n",
    "\n",
    "# Now we add the outlet to the list (IF it was not before):\n",
    "# Ensure that the basin_id is in the nested_catchments\n",
    "for basin_id in nested_catchments.index:\n",
    "    if basin_id not in nested_catchments.at[basin_id, 'nested_catchments']:\n",
    "        nested_catchments.at[basin_id, 'nested_catchments'].append(basin_id)\n",
    "\n",
    "\n",
    "# Convert to list both the nested_catchments and the duplicated_suspect columns\n",
    "estreams_attributes['nested_catchments'] = estreams_attributes['nested_catchments'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "\n",
    "# Remove the brackets and handle NaN values\n",
    "estreams_attributes['duplicated_suspect'] = estreams_attributes['duplicated_suspect'].apply(\n",
    "    lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \") if isinstance(x, str) else x)\n",
    "\n",
    "estreams_attributes.sort_index(inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b555f44",
   "metadata": {},
   "source": [
    "### Geological data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d63e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map permeability classes to corresponding columns\n",
    "permeability_columns = {\n",
    "    \"high\": [\"lit_fra_Alluvium\", 'lit_fra_Coal', 'lit_fra_Conglomerate', 'lit_fra_Gravel and sand',\n",
    "             'lit_fra_Sand', 'lit_fra_Sand and gravel', 'lit_fra_Sandstone and conglomerate', 'lit_fra_Sandstone'\n",
    "        ],\n",
    "    \n",
    "    \"medium\": ['lit_fra_Limestone', 'lit_fra_Sandstone and marl', 'lit_fra_Sandstone and schist',\n",
    "              'lit_fra_Sandstone, conglomerate and marl',\n",
    "\n",
    "              'lit_fra_Arkose', 'lit_fra_Dolomite rock', 'lit_fra_Limestone and marl', 'lit_fra_Marl', \n",
    "             'lit_fra_Marl and dolomite', 'lit_fra_Marl and limestone', 'lit_fra_Marl and sandstone',\n",
    "               'lit_fra_Sandstone and siltstone', 'lit_fra_Sandstone, siltstone and schist', \n",
    "              'lit_fra_Schist and sandstone', 'lit_fra_Silt',  'lit_fra_Silt and schist', 'lit_fra_Siltstone, sandstone and schist'\n",
    "              \n",
    "             ],\n",
    "    \n",
    "    \"low\": ['lit_fra_Cristallin basement', 'lit_fra_Plutonic rock',  'lit_fra_Quarzite',\n",
    "                    'lit_fra_Schist','lit_fra_Volcanic rock' \n",
    "                   ]\n",
    "}\n",
    "\n",
    "# Iterate over the permeability columns and calculate the area for each class\n",
    "for permeability_class, columns in permeability_columns.items():\n",
    "    geology_regional_31_classes_moselle[f'area_perm_{permeability_class}'] = geology_regional_31_classes_moselle[columns].sum(axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "geology_regional_31_classes_moselle = geology_regional_31_classes_moselle[[\"area_perm_high\", \"area_perm_medium\", \"area_perm_low\"]]\n",
    "\n",
    "# Rename the columns\n",
    "geology_regional_31_classes_moselle.columns = [\"perm_high_regi\", \"perm_medium_regi\", \"perm_low_regi\"]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "geology_regional_31_classes_moselle\n",
    "\n",
    "geology_regional_31_classes_moselle[\"baseflow_index\"] = estreams_attributes[\"baseflow_index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a124827",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c1bc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation\n",
    "estreams_attributes[[\"perm_high_regi\", \"perm_medium_regi\", \"perm_low_regi\"]] = geology_regional_31_classes_moselle[[\"perm_high_regi\", \"perm_medium_regi\", \"perm_low_regi\"]]\n",
    "\n",
    "estreams_attributes[\"perm_high_glob2\"] = estreams_attributes[\"perm_high_glob\"]\n",
    "estreams_attributes[\"perm_medium_glob2\"] = estreams_attributes[\"perm_medium_glob\"] + estreams_attributes[\"perm_low_glob\"]\n",
    "estreams_attributes[\"perm_low_glob2\"] = estreams_attributes[\"perm_verylow_glob\"]\n",
    "\n",
    "estreams_attributes[\"perm_high_cont2\"] = estreams_attributes[\"perm_high_cont\"]\n",
    "estreams_attributes[\"perm_medium_cont2\"] = estreams_attributes[\"perm_medium_cont\"] + estreams_attributes[\"perm_low_cont\"]\n",
    "estreams_attributes[\"perm_low_cont2\"] = estreams_attributes[\"perm_verylow_cont\"]\n",
    "\n",
    "\n",
    "for basin_id in estreams_attributes.index.tolist():\n",
    "\n",
    "    # Extract and divide by 100\n",
    "    v1 = estreams_attributes.loc[basin_id, \"perm_high_regi\"] / 100\n",
    "    v2 = estreams_attributes.loc[basin_id, \"perm_medium_regi\"] / 100\n",
    "    v3 = estreams_attributes.loc[basin_id, \"perm_low_regi\"] / 100\n",
    "\n",
    "    # Round all values to one decimal place\n",
    "    v1 = round(v1, 2)\n",
    "    v2 = round(v2, 2)\n",
    "    v3 = round(v3, 2)\n",
    "\n",
    "    # Ensure the sum is exactly 1 by adjusting the largest value\n",
    "    diff = 1 - (v1 + v2 + v3)\n",
    "\n",
    "    if diff != 0:\n",
    "        # Adjust the value that was the largest before rounding\n",
    "        if max(v1, v2, v3) == v1:\n",
    "            v1 += diff\n",
    "        elif max(v1, v2, v3) == v2:\n",
    "            v2 += diff\n",
    "        else:\n",
    "            v3 += diff\n",
    "\n",
    "    # Assign back\n",
    "    estreams_attributes.loc[basin_id, \"perm_high_regi\"] = v1 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_medium_regi\"] = v2 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_low_regi\"] = v3 * 100\n",
    "\n",
    "\n",
    "for basin_id in estreams_attributes.index.tolist():\n",
    "\n",
    "    # Extract and divide by 100\n",
    "    v1 = estreams_attributes.loc[basin_id, \"perm_high_glob2\"] / 100\n",
    "    v2 = estreams_attributes.loc[basin_id, \"perm_medium_glob2\"] / 100\n",
    "    v3 = estreams_attributes.loc[basin_id, \"perm_low_glob2\"] / 100\n",
    "\n",
    "    # Round all values to one decimal place\n",
    "    v1 = round(v1, 2)\n",
    "    v2 = round(v2, 2)\n",
    "    v3 = round(v3, 2)\n",
    "\n",
    "    # Ensure the sum is exactly 1 by adjusting the largest value\n",
    "    diff = 1 - (v1 + v2 + v3)\n",
    "\n",
    "    if diff != 0:\n",
    "        # Adjust the value that was the largest before rounding\n",
    "        if max(v1, v2, v3) == v1:\n",
    "            v1 += diff\n",
    "        elif max(v1, v2, v3) == v2:\n",
    "            v2 += diff\n",
    "        else:\n",
    "            v3 += diff\n",
    "\n",
    "    # Assign back\n",
    "    estreams_attributes.loc[basin_id, \"perm_high_glob2\"] = v1 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_medium_glob2\"] = v2 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_low_glob2\"] = v3 * 100\n",
    "\n",
    "for basin_id in estreams_attributes.index.tolist():\n",
    "\n",
    "    # Extract and divide by 100\n",
    "    v1 = estreams_attributes.loc[basin_id, \"perm_high_cont2\"] / 100\n",
    "    v2 = estreams_attributes.loc[basin_id, \"perm_medium_cont2\"] / 100\n",
    "    v3 = estreams_attributes.loc[basin_id, \"perm_low_cont2\"] / 100\n",
    "\n",
    "    # Round all values to one decimal place\n",
    "    v1 = round(v1, 2)\n",
    "    v2 = round(v2, 2)\n",
    "    v3 = round(v3, 2)\n",
    "\n",
    "    # Ensure the sum is exactly 1 by adjusting the largest value\n",
    "    diff = 1 - (v1 + v2 + v3)\n",
    "\n",
    "    if diff != 0:\n",
    "        # Adjust the value that was the largest before rounding\n",
    "        if max(v1, v2, v3) == v1:\n",
    "            v1 += diff\n",
    "        elif max(v1, v2, v3) == v2:\n",
    "            v2 += diff\n",
    "        else:\n",
    "            v3 += diff\n",
    "\n",
    "    # Assign back\n",
    "    estreams_attributes.loc[basin_id, \"perm_high_cont2\"] = v1 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_medium_cont2\"] = v2 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_low_cont2\"] = v3 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c307acb",
   "metadata": {},
   "source": [
    "### Further filter of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c310a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_id</th>\n",
       "      <th>gauge_name</th>\n",
       "      <th>gauge_country</th>\n",
       "      <th>gauge_provider</th>\n",
       "      <th>river</th>\n",
       "      <th>lon_snap</th>\n",
       "      <th>lat_snap</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>elevation</th>\n",
       "      <th>...</th>\n",
       "      <th>stations_num_p_mean</th>\n",
       "      <th>perm_high_regi</th>\n",
       "      <th>perm_medium_regi</th>\n",
       "      <th>perm_low_regi</th>\n",
       "      <th>perm_high_glob2</th>\n",
       "      <th>perm_medium_glob2</th>\n",
       "      <th>perm_low_glob2</th>\n",
       "      <th>perm_high_cont2</th>\n",
       "      <th>perm_medium_cont2</th>\n",
       "      <th>perm_low_cont2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basin_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BEWA0066</th>\n",
       "      <td>99141002</td>\n",
       "      <td>Reuland</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE_SPW</td>\n",
       "      <td>Our</td>\n",
       "      <td>6.151802</td>\n",
       "      <td>50.188258</td>\n",
       "      <td>6.151802</td>\n",
       "      <td>50.188258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEWA0067</th>\n",
       "      <td>99261002</td>\n",
       "      <td>Schoenberg</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE_SPW</td>\n",
       "      <td>Our</td>\n",
       "      <td>6.263467</td>\n",
       "      <td>50.289277</td>\n",
       "      <td>6.263467</td>\n",
       "      <td>50.289277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEWA0087</th>\n",
       "      <td>56100000</td>\n",
       "      <td>Martelange</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE_SPW</td>\n",
       "      <td>Sure</td>\n",
       "      <td>5.739269</td>\n",
       "      <td>49.833704</td>\n",
       "      <td>5.739269</td>\n",
       "      <td>49.833704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEWA0106</th>\n",
       "      <td>60800000</td>\n",
       "      <td>Reuland</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE_SPW</td>\n",
       "      <td>Ulf</td>\n",
       "      <td>6.150669</td>\n",
       "      <td>50.196522</td>\n",
       "      <td>6.150669</td>\n",
       "      <td>50.196522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEWA0107</th>\n",
       "      <td>60900000</td>\n",
       "      <td>Lommersweiler</td>\n",
       "      <td>BE</td>\n",
       "      <td>BE_SPW</td>\n",
       "      <td>Braunlauf</td>\n",
       "      <td>6.153292</td>\n",
       "      <td>50.235014</td>\n",
       "      <td>6.153955</td>\n",
       "      <td>50.234494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU000015</th>\n",
       "      <td>34</td>\n",
       "      <td>Michelau</td>\n",
       "      <td>LU</td>\n",
       "      <td>LU_CONTACTFORM</td>\n",
       "      <td>Sure</td>\n",
       "      <td>6.091178</td>\n",
       "      <td>49.895421</td>\n",
       "      <td>6.091178</td>\n",
       "      <td>49.895421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU000016</th>\n",
       "      <td>3</td>\n",
       "      <td>Pfaffenthal</td>\n",
       "      <td>LU</td>\n",
       "      <td>LU_CONTACTFORM</td>\n",
       "      <td>Alzette</td>\n",
       "      <td>6.132266</td>\n",
       "      <td>49.620647</td>\n",
       "      <td>6.132266</td>\n",
       "      <td>49.620647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU000017</th>\n",
       "      <td>16</td>\n",
       "      <td>Rosport</td>\n",
       "      <td>LU</td>\n",
       "      <td>LU_CONTACTFORM</td>\n",
       "      <td>Sure</td>\n",
       "      <td>6.509851</td>\n",
       "      <td>49.785883</td>\n",
       "      <td>6.509851</td>\n",
       "      <td>49.785883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU000018</th>\n",
       "      <td>5</td>\n",
       "      <td>Schoenfels</td>\n",
       "      <td>LU</td>\n",
       "      <td>LU_CONTACTFORM</td>\n",
       "      <td>Mamer</td>\n",
       "      <td>6.100795</td>\n",
       "      <td>49.723112</td>\n",
       "      <td>6.100795</td>\n",
       "      <td>49.723112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU000019</th>\n",
       "      <td>12</td>\n",
       "      <td>Vianden</td>\n",
       "      <td>LU</td>\n",
       "      <td>LU_CONTACTFORM</td>\n",
       "      <td>Our</td>\n",
       "      <td>6.204738</td>\n",
       "      <td>49.939224</td>\n",
       "      <td>6.204738</td>\n",
       "      <td>49.939224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gauge_id     gauge_name gauge_country  gauge_provider      river  \\\n",
       "basin_id                                                                     \n",
       "BEWA0066  99141002        Reuland            BE          BE_SPW        Our   \n",
       "BEWA0067  99261002     Schoenberg            BE          BE_SPW        Our   \n",
       "BEWA0087  56100000     Martelange            BE          BE_SPW       Sure   \n",
       "BEWA0106  60800000        Reuland            BE          BE_SPW        Ulf   \n",
       "BEWA0107  60900000  Lommersweiler            BE          BE_SPW  Braunlauf   \n",
       "...            ...            ...           ...             ...        ...   \n",
       "LU000015        34       Michelau            LU  LU_CONTACTFORM       Sure   \n",
       "LU000016         3    Pfaffenthal            LU  LU_CONTACTFORM    Alzette   \n",
       "LU000017        16        Rosport            LU  LU_CONTACTFORM       Sure   \n",
       "LU000018         5     Schoenfels            LU  LU_CONTACTFORM      Mamer   \n",
       "LU000019        12        Vianden            LU  LU_CONTACTFORM        Our   \n",
       "\n",
       "          lon_snap   lat_snap       lon        lat elevation  ...  \\\n",
       "basin_id                                                      ...   \n",
       "BEWA0066  6.151802  50.188258  6.151802  50.188258       NaN  ...   \n",
       "BEWA0067  6.263467  50.289277  6.263467  50.289277       NaN  ...   \n",
       "BEWA0087  5.739269  49.833704  5.739269  49.833704       NaN  ...   \n",
       "BEWA0106  6.150669  50.196522  6.150669  50.196522       NaN  ...   \n",
       "BEWA0107  6.153292  50.235014  6.153955  50.234494       NaN  ...   \n",
       "...            ...        ...       ...        ...       ...  ...   \n",
       "LU000015  6.091178  49.895421  6.091178  49.895421       NaN  ...   \n",
       "LU000016  6.132266  49.620647  6.132266  49.620647       NaN  ...   \n",
       "LU000017  6.509851  49.785883  6.509851  49.785883       NaN  ...   \n",
       "LU000018  6.100795  49.723112  6.100795  49.723112       NaN  ...   \n",
       "LU000019  6.204738  49.939224  6.204738  49.939224       NaN  ...   \n",
       "\n",
       "          stations_num_p_mean  perm_high_regi  perm_medium_regi  \\\n",
       "basin_id                                                          \n",
       "BEWA0066                 16.0             3.0               3.0   \n",
       "BEWA0067                  8.0             2.0               0.0   \n",
       "BEWA0087                  6.0             0.0               0.0   \n",
       "BEWA0106                  9.0             0.0               0.0   \n",
       "BEWA0107                  6.0             4.0              15.0   \n",
       "...                       ...             ...               ...   \n",
       "LU000015                 25.0             2.0               0.0   \n",
       "LU000016                 15.0            14.0              86.0   \n",
       "LU000017                 78.0            19.0              31.0   \n",
       "LU000018                 17.0            39.0              61.0   \n",
       "LU000019                 27.0             4.0               4.0   \n",
       "\n",
       "          perm_low_regi perm_high_glob2 perm_medium_glob2  perm_low_glob2  \\\n",
       "basin_id                                                                    \n",
       "BEWA0066           94.0            75.0              25.0             0.0   \n",
       "BEWA0067           98.0            64.0              36.0             0.0   \n",
       "BEWA0087          100.0           100.0               0.0             0.0   \n",
       "BEWA0106          100.0           100.0               0.0             0.0   \n",
       "BEWA0107           81.0           100.0               0.0             0.0   \n",
       "...                 ...             ...               ...             ...   \n",
       "LU000015           98.0           100.0               0.0             0.0   \n",
       "LU000016            0.0             0.0             100.0             0.0   \n",
       "LU000017           50.0            41.0              59.0             0.0   \n",
       "LU000018            0.0             0.0             100.0             0.0   \n",
       "LU000019           92.0            59.0              41.0             0.0   \n",
       "\n",
       "          perm_high_cont2  perm_medium_cont2  perm_low_cont2  \n",
       "basin_id                                                      \n",
       "BEWA0066              0.0                0.0           100.0  \n",
       "BEWA0067              0.0                0.0           100.0  \n",
       "BEWA0087              0.0                0.0           100.0  \n",
       "BEWA0106              0.0                0.0           100.0  \n",
       "BEWA0107              0.0                0.0           100.0  \n",
       "...                   ...                ...             ...  \n",
       "LU000015              0.0                0.0           100.0  \n",
       "LU000016             16.0               84.0             0.0  \n",
       "LU000017             18.0               29.0            53.0  \n",
       "LU000018             85.0               15.0             0.0  \n",
       "LU000019              0.0                0.0           100.0  \n",
       "\n",
       "[152 rows x 128 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we define the outlet of the Moselle to be used\n",
    "outlets = [\"DEBU1959\"]\n",
    "nested_cats_df = nested_catchments.loc[outlets, :]\n",
    "\n",
    "# Now we save our dataframes in a dictionary of dataframes. One dataframe for each watershed. \n",
    "\n",
    "nested_cats_filtered = find_max_unique_rows(nested_cats_df)                                  # Filter only the catchemnts using the function stated before\n",
    "nested_cats_filtered_df = nested_catchments.loc[nested_cats_filtered, :]                     # Here we filter the catchemnts for the list (again, after we apply our function):\n",
    "\n",
    "# Store the variables for the selected catchments in a list of dataframes now for only the ones above 20 cats:\n",
    "estreams_attributes_dfs = {}\n",
    "for catchment in tqdm.tqdm(nested_cats_filtered):\n",
    "    # Retrieve the nested list of catchments for the current catchment\n",
    "    nested_clip = nested_cats_filtered_df.loc[catchment, 'nested_catchments']\n",
    "    \n",
    "    # Filter values to include only those that exist in the index of estreams_attributes\n",
    "    nested_clip = [value for value in nested_clip if value in estreams_attributes.index]\n",
    "    \n",
    "    # Filter the estreams_attributes DataFrame based on the filtered nested_clip\n",
    "    cat_clip = estreams_attributes.loc[nested_clip, :]\n",
    "    \n",
    "    # Store the resulting DataFrame in the dictionary\n",
    "    estreams_attributes_dfs[catchment] = cat_clip\n",
    "\n",
    "# Here we can save the length of each watershed (number of nested catchemnts)\n",
    "catchment_lens = pd.DataFrame(index = estreams_attributes_dfs.keys())\n",
    "for catchment, data in estreams_attributes_dfs.items():\n",
    "    catchment_lens.loc[catchment, \"len\"] = len(data)\n",
    "\n",
    "# Now we can filter it properly:\n",
    "nested_cats_filtered_abovevalue = catchment_lens[catchment_lens.len >= 10]\n",
    "\n",
    "# # Here we filter the catchemnts for the list (again, after we apply our function):\n",
    "nested_cats_filtered_abovevalue_df = nested_catchments.loc[nested_cats_filtered_abovevalue.index, :]\n",
    "\n",
    "# Store the variables for the selected catchments in a list of dataframes now for only the ones above 20 cats:\n",
    "estreams_attributes_dfs = {}\n",
    "\n",
    "for catchment in tqdm.tqdm(nested_cats_filtered_abovevalue_df.index):\n",
    "    # Retrieve the nested list of catchments for the current catchment\n",
    "    nested_clip = nested_cats_filtered_abovevalue_df.loc[catchment, 'nested_catchments']\n",
    "    \n",
    "    # Filter values to include only those that exist in the index of estreams_attributes\n",
    "    nested_clip = [value for value in nested_clip if value in estreams_attributes.index]\n",
    "    \n",
    "    # Filter the estreams_attributes DataFrame based on the filtered nested_clip\n",
    "    cat_clip = estreams_attributes.loc[nested_clip, :]\n",
    "    \n",
    "    # Store the resulting DataFrame in the dictionary\n",
    "    estreams_attributes_dfs[catchment] = cat_clip\n",
    "\n",
    "estreams_attributes_dfs[\"DEBU1959\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b412dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "estreams_attributes_clipped = estreams_attributes_dfs[\"DEBU1959\"]\n",
    "catchments_ids = estreams_attributes_clipped.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52941a1b",
   "metadata": {},
   "source": [
    "## Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c47eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [06:46<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary\n",
    "inputs = {}\n",
    "observations = {}\n",
    "areas = {}\n",
    "perm_areas = {}\n",
    "quality_masks = {}\n",
    "rootdepth_mean = {}\n",
    "waterdeficit_mean = {}\n",
    "perm_areasglobal = {}\n",
    "perm_areascontinental = {}\n",
    "prec_mean = {}\n",
    "\n",
    "# Function to compute S_dem per water year\n",
    "def compute_S_dem(group):\n",
    "    group = group.copy()\n",
    "    group.iloc[0, group.columns.get_loc('S_dem(t-1)')] = 0\n",
    "    group.iloc[0, group.columns.get_loc('S_dem(t)')] = max(\n",
    "        0, group.iloc[0]['S_dem(t-1)'] + (group.iloc[0]['pet_mean'] - group.iloc[0]['p_mean'])\n",
    "    )\n",
    "\n",
    "    for i in range(1, len(group)):\n",
    "        group.iloc[i, group.columns.get_loc('S_dem(t-1)')] = group.iloc[i - 1]['S_dem(t)']\n",
    "        group.iloc[i, group.columns.get_loc('S_dem(t)')] = max(\n",
    "            0, group.iloc[i]['S_dem(t-1)'] + (group.iloc[i]['pet_mean'] - group.iloc[i]['p_mean'])\n",
    "        )\n",
    "\n",
    "    return group\n",
    "\n",
    "\n",
    "for basin_id in tqdm.tqdm(catchments_ids):\n",
    "    \n",
    "    data = pd.read_csv(r\"C:\\Users\\nascimth\\Documents\\Thiago\\Eawag\\Python\\Data\\data\"+\"\\estreams_timeseries_\"+basin_id+\".csv\", index_col=0)\n",
    "\n",
    "    area = network_estreams.loc[basin_id, \"area_estreams\"]\n",
    "\n",
    "    data[\"Q\"] = data.loc[:, \"q_mean\"]\n",
    "    data[\"Q\"] = (data.Q * 86400 * 1000) / (area * 1000000)\n",
    "\n",
    "    # Define the subset to be used:\n",
    "    #data = data.loc[\"1988\":\"2001\", :]\n",
    "    data = data.loc[\"2001-10-01\":\"2015-09-30\"]\n",
    "\n",
    "\n",
    "    # Interpolate when needed:\n",
    "    data['pet_mean'] = data['pet_mean'].interpolate()\n",
    "    data['t_mean'] = data['t_mean'].interpolate()\n",
    "    data['p_mean'] = data['p_mean'].interpolate()\n",
    "\n",
    "\n",
    "    data_wd = data.copy()\n",
    "    data_wd.index = pd.to_datetime(data_wd.index)\n",
    "\n",
    "    # Define water year (Oct 1 to Sept 30)\n",
    "\n",
    "    data_wd['water_year'] = np.where(data_wd.index.month >= 10, data_wd.index.year + 1, data_wd.index.year)\n",
    "    data_wd['S_dem(t-1)'] = np.nan\n",
    "    data_wd['S_dem(t)'] = np.nan\n",
    "\n",
    "    # Apply computation per water year\n",
    "    data_wd = data_wd.groupby('water_year', group_keys=False).apply(compute_S_dem)\n",
    "    \n",
    "    # Compute the 75% quantile of 'S_dem(t)' per water year\n",
    "    S_dem_75_per_year = data_wd.groupby('water_year')['S_dem(t)'].max()\n",
    "    S_dem_75_per_year = S_dem_75_per_year.quantile(0.75)\n",
    "\n",
    "    # Save the variables:\n",
    "    Q_obs = data.loc[:, \"Q\"].values\n",
    "    P = data.loc[:, \"p_mean\"].values\n",
    "    E = data.loc[:, \"pet_mean\"].values\n",
    "    T = data.loc[:, \"t_mean\"].values\n",
    "    quality =  (pd.isna(Q_obs)).astype(int)\n",
    "\n",
    "    inputs[basin_id] = [P, T, E]\n",
    "    observations[basin_id] = Q_obs\n",
    "    areas[basin_id] = area\n",
    "    perm_areas[basin_id] = [round(estreams_attributes.loc[basin_id, \"perm_high_regi\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_medium_regi\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_low_regi\"] / 100, 2)]\n",
    "    \n",
    "    perm_areasglobal[basin_id] = [round(estreams_attributes.loc[basin_id, \"perm_high_glob2\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_medium_glob2\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_low_glob2\"] / 100, 2)]\n",
    "    \n",
    "    perm_areascontinental[basin_id] = [round(estreams_attributes.loc[basin_id, \"perm_high_cont2\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_medium_cont2\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_low_cont2\"] / 100, 2)]\n",
    "\n",
    "    quality_masks[basin_id] = quality\n",
    "    rootdepth_mean[basin_id] = estreams_attributes.loc[basin_id, \"root_dep_mean\"]\n",
    "    waterdeficit_mean[basin_id] = np.float64(round(S_dem_75_per_year, 1))\n",
    "    prec_mean[basin_id] = estreams_attributes.loc[basin_id, \"p_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionaries\n",
    "path_inputs = r'C:\\Users\\nascimth\\Documents\\Thiago\\Eawag\\Python\\Scripts\\estreams_superflexpy\\data\\models\\input\\subset_2001_2015'\n",
    "\n",
    "np.save(path_inputs+'\\\\inputs.npy', inputs)\n",
    "np.save(path_inputs+'\\\\observations.npy', observations)\n",
    "np.save(path_inputs+'\\\\areas.npy', areas)\n",
    "np.save(path_inputs+'\\\\perm_areas.npy', perm_areas)\n",
    "np.save(path_inputs+'\\\\quality_masks.npy', quality_masks)\n",
    "np.save(path_inputs+'\\\\rootdepth_mean.npy', rootdepth_mean)\n",
    "np.save(path_inputs+'\\\\waterdeficit_mean.npy', waterdeficit_mean)\n",
    "np.save(path_inputs+'\\\\perm_areasglobal.npy', perm_areasglobal)\n",
    "np.save(path_inputs+'\\\\perm_areascontinental.npy', perm_areascontinental)\n",
    "np.save(path_inputs+'\\\\prec_mean.npy', prec_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb69fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [06:12<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary\n",
    "inputs = {}\n",
    "observations = {}\n",
    "areas = {}\n",
    "perm_areas = {}\n",
    "quality_masks = {}\n",
    "rootdepth_mean = {}\n",
    "waterdeficit_mean = {}\n",
    "perm_areasglobal = {}\n",
    "perm_areascontinental = {}\n",
    "prec_mean = {}\n",
    "\n",
    "# Function to compute S_dem per water year\n",
    "def compute_S_dem(group):\n",
    "    group = group.copy()\n",
    "    group.iloc[0, group.columns.get_loc('S_dem(t-1)')] = 0\n",
    "    group.iloc[0, group.columns.get_loc('S_dem(t)')] = max(\n",
    "        0, group.iloc[0]['S_dem(t-1)'] + (group.iloc[0]['pet_mean'] - group.iloc[0]['p_mean'])\n",
    "    )\n",
    "\n",
    "    for i in range(1, len(group)):\n",
    "        group.iloc[i, group.columns.get_loc('S_dem(t-1)')] = group.iloc[i - 1]['S_dem(t)']\n",
    "        group.iloc[i, group.columns.get_loc('S_dem(t)')] = max(\n",
    "            0, group.iloc[i]['S_dem(t-1)'] + (group.iloc[i]['pet_mean'] - group.iloc[i]['p_mean'])\n",
    "        )\n",
    "\n",
    "    return group\n",
    "\n",
    "\n",
    "for basin_id in tqdm.tqdm(catchments_ids):\n",
    "    \n",
    "    data = pd.read_csv(r\"C:\\Users\\nascimth\\Documents\\Thiago\\Eawag\\Python\\Data\\data\"+\"\\estreams_timeseries_\"+basin_id+\".csv\", index_col=0)\n",
    "\n",
    "    area = network_estreams.loc[basin_id, \"area_estreams\"]\n",
    "\n",
    "    data[\"Q\"] = data.loc[:, \"q_mean\"]\n",
    "    data[\"Q\"] = (data.Q * 86400 * 1000) / (area * 1000000)\n",
    "\n",
    "    # Define the subset to be used:\n",
    "    data = data.loc[\"1988-10-01\":\"2001-09-30\", :]\n",
    "    #data = data.loc[\"2001-10-01\":\"2015-09-30\"]\n",
    "\n",
    "\n",
    "    # Interpolate when needed:\n",
    "    data['pet_mean'] = data['pet_mean'].interpolate()\n",
    "    data['t_mean'] = data['t_mean'].interpolate()\n",
    "    data['p_mean'] = data['p_mean'].interpolate()\n",
    "\n",
    "\n",
    "    data_wd = data.copy()\n",
    "    data_wd.index = pd.to_datetime(data_wd.index)\n",
    "\n",
    "    # Define water year (Oct 1 to Sept 30)\n",
    "\n",
    "    data_wd['water_year'] = np.where(data_wd.index.month >= 10, data_wd.index.year + 1, data_wd.index.year)\n",
    "    data_wd['S_dem(t-1)'] = np.nan\n",
    "    data_wd['S_dem(t)'] = np.nan\n",
    "\n",
    "    # Apply computation per water year\n",
    "    data_wd = data_wd.groupby('water_year', group_keys=False).apply(compute_S_dem)\n",
    "    \n",
    "    # Compute the 75% quantile of 'S_dem(t)' per water year\n",
    "    S_dem_75_per_year = data_wd.groupby('water_year')['S_dem(t)'].max()\n",
    "    S_dem_75_per_year = S_dem_75_per_year.quantile(0.75)\n",
    "\n",
    "    # Save the variables:\n",
    "    Q_obs = data.loc[:, \"Q\"].values\n",
    "    P = data.loc[:, \"p_mean\"].values\n",
    "    E = data.loc[:, \"pet_mean\"].values\n",
    "    T = data.loc[:, \"t_mean\"].values\n",
    "    quality =  (pd.isna(Q_obs)).astype(int)\n",
    "\n",
    "    inputs[basin_id] = [P, T, E]\n",
    "    observations[basin_id] = Q_obs\n",
    "    areas[basin_id] = area\n",
    "    perm_areas[basin_id] = [round(estreams_attributes.loc[basin_id, \"perm_high_regi\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_medium_regi\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_low_regi\"] / 100, 2)]\n",
    "    \n",
    "    perm_areasglobal[basin_id] = [round(estreams_attributes.loc[basin_id, \"perm_high_glob2\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_medium_glob2\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_low_glob2\"] / 100, 2)]\n",
    "    \n",
    "    perm_areascontinental[basin_id] = [round(estreams_attributes.loc[basin_id, \"perm_high_cont2\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_medium_cont2\"] / 100, 2), \n",
    "                            round(estreams_attributes.loc[basin_id, \"perm_low_cont2\"] / 100, 2)]\n",
    "\n",
    "    quality_masks[basin_id] = quality\n",
    "    rootdepth_mean[basin_id] = estreams_attributes.loc[basin_id, \"root_dep_mean\"]\n",
    "    waterdeficit_mean[basin_id] = np.float64(round(S_dem_75_per_year, 1))\n",
    "    prec_mean[basin_id] = estreams_attributes.loc[basin_id, \"p_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e836201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionaries\n",
    "path_inputs = r'C:\\Users\\nascimth\\Documents\\Thiago\\Eawag\\Python\\Scripts\\estreams_superflexpy\\data\\models\\input\\subset_1988_2001'\n",
    "\n",
    "np.save(path_inputs+'\\\\inputs.npy', inputs)\n",
    "np.save(path_inputs+'\\\\observations.npy', observations)\n",
    "np.save(path_inputs+'\\\\areas.npy', areas)\n",
    "np.save(path_inputs+'\\\\perm_areas.npy', perm_areas)\n",
    "np.save(path_inputs+'\\\\quality_masks.npy', quality_masks)\n",
    "np.save(path_inputs+'\\\\rootdepth_mean.npy', rootdepth_mean)\n",
    "np.save(path_inputs+'\\\\waterdeficit_mean.npy', waterdeficit_mean)\n",
    "np.save(path_inputs+'\\\\perm_areasglobal.npy', perm_areasglobal)\n",
    "np.save(path_inputs+'\\\\perm_areascontinental.npy', perm_areascontinental)\n",
    "np.save(path_inputs+'\\\\prec_mean.npy', prec_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd8d51",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
