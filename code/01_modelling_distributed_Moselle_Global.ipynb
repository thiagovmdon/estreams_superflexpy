{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068701ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spotpy\n",
    "import time\n",
    "import os\n",
    "import tqdm as tqdm\n",
    "import hydroanalysis\n",
    "from utils.functions import find_max_unique_rows\n",
    "from utils.functions import find_iterative_immediate_downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f535bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superflexpy things\n",
    "from david2022 import FastReservoirPower, FastReservoirLinear\n",
    "from superflexpy.framework.unit import Unit\n",
    "from superflexpy.framework.node import Node\n",
    "from superflexpy.framework.network import Network\n",
    "\n",
    "from superflexpy.implementation.elements.hbv import UnsaturatedReservoir, PowerReservoir\n",
    "\n",
    "from superflexpy.implementation.numerical_approximators.implicit_euler import ImplicitEulerPython\n",
    "from superflexpy.implementation.root_finders.pegasus import PegasusPython\n",
    "\n",
    "# Numba implementation:\n",
    "from superflexpy.implementation.root_finders.pegasus import PegasusNumba\n",
    "from superflexpy.implementation.numerical_approximators.implicit_euler import ImplicitEulerNumba\n",
    "\n",
    "from superflexpy.implementation.elements.hbv import PowerReservoir\n",
    "from superflexpy.framework.unit import Unit\n",
    "from superflexpy.implementation.elements.thur_model_hess import SnowReservoir, UnsaturatedReservoir, PowerReservoir, HalfTriangularLag\n",
    "\n",
    "from superflexpy.implementation.elements.structure_elements import Transparent, Junction, Splitter\n",
    "from superflexpy.framework.element import ParameterizedElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_estreams = r'C:\\Users\\nascimth\\Documents\\Thiago\\Eawag\\Python\\Scripts\\estreams_part_b\\data\\EStreams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset network\n",
    "network_estreams = pd.read_csv(path_estreams+'\\streamflow_gauges/estreams_gauging_stations.csv', encoding='utf-8')\n",
    "network_estreams.set_index(\"basin_id\", inplace = True)\n",
    "\n",
    "# Convert 'date_column' and 'time_column' to datetime\n",
    "network_estreams['start_date'] = pd.to_datetime(network_estreams['start_date'])\n",
    "network_estreams['end_date'] = pd.to_datetime(network_estreams['end_date'])\n",
    "\n",
    "# Convert to list both the nested_catchments and the duplicated_suspect columns\n",
    "network_estreams['nested_catchments'] = network_estreams['nested_catchments'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "\n",
    "# Remove the brackets and handle NaN values\n",
    "network_estreams['duplicated_suspect'] = network_estreams['duplicated_suspect'].apply(\n",
    "    lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \") if isinstance(x, str) else x)\n",
    "\n",
    "# Set the nested catchments as a dataframe\n",
    "nested_catchments = pd.DataFrame(network_estreams['nested_catchments'])\n",
    "\n",
    "# Now we add the outlet to the list (IF it was not before):\n",
    "# Ensure that the basin_id is in the nested_catchments\n",
    "for basin_id in nested_catchments.index:\n",
    "    if basin_id not in nested_catchments.at[basin_id, 'nested_catchments']:\n",
    "        nested_catchments.at[basin_id, 'nested_catchments'].append(basin_id)\n",
    "\n",
    "# Attributes already filtered previously:\n",
    "#estreams_attributes = pd.read_csv('data/exploration/estreams_attributes_filtered_moselle_sm_su_tog.csv', encoding='utf-8')\n",
    "estreams_attributes = pd.read_csv('../data/filtered_dataset/estreams_attributes_filtered_quality_geology_v01.csv', encoding='utf-8')\n",
    "\n",
    "estreams_attributes.set_index(\"basin_id\", inplace = True)\n",
    "\n",
    "# Convert to list both the nested_catchments and the duplicated_suspect columns\n",
    "estreams_attributes['nested_catchments'] = estreams_attributes['nested_catchments'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "\n",
    "# Remove the brackets and handle NaN values\n",
    "estreams_attributes['duplicated_suspect'] = estreams_attributes['duplicated_suspect'].apply(\n",
    "    lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \") if isinstance(x, str) else x)\n",
    "\n",
    "estreams_attributes.sort_index(inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d63e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geological attributes (regional scale)\n",
    "geology_regional_31_classes_moselle = pd.read_csv(\"../data/estreams_geology_moselle_regional_attributes.csv\", encoding='utf-8')\n",
    "\n",
    "geology_regional_31_classes_moselle.set_index(\"basin_id\", inplace = True)\n",
    "\n",
    "# Create a dictionary to map permeability classes to corresponding columns\n",
    "permeability_columns = {\n",
    "    \"high\": [\"lit_fra_Alluvium\", 'lit_fra_Coal', 'lit_fra_Conglomerate', 'lit_fra_Gravel and sand',\n",
    "             'lit_fra_Sand', 'lit_fra_Sand and gravel', 'lit_fra_Sandstone and conglomerate', 'lit_fra_Sandstone'\n",
    "        ],\n",
    "    \n",
    "    \"medium\": ['lit_fra_Limestone', 'lit_fra_Sandstone and marl', 'lit_fra_Sandstone and schist',\n",
    "              'lit_fra_Sandstone, conglomerate and marl',\n",
    "\n",
    "              'lit_fra_Arkose', 'lit_fra_Dolomite rock', 'lit_fra_Limestone and marl', 'lit_fra_Marl', \n",
    "             'lit_fra_Marl and dolomite', 'lit_fra_Marl and limestone', 'lit_fra_Marl and sandstone',\n",
    "               'lit_fra_Sandstone and siltstone', 'lit_fra_Sandstone, siltstone and schist', \n",
    "              'lit_fra_Schist and sandstone', 'lit_fra_Silt',  'lit_fra_Silt and schist', 'lit_fra_Siltstone, sandstone and schist'\n",
    "              \n",
    "             ],\n",
    "    \n",
    "    \"low\": ['lit_fra_Cristallin basement', 'lit_fra_Plutonic rock',  'lit_fra_Quarzite',\n",
    "                    'lit_fra_Schist','lit_fra_Volcanic rock' \n",
    "                   ]\n",
    "}\n",
    "\n",
    "# Iterate over the permeability columns and calculate the area for each class\n",
    "for permeability_class, columns in permeability_columns.items():\n",
    "    geology_regional_31_classes_moselle[f'area_perm_{permeability_class}'] = geology_regional_31_classes_moselle[columns].sum(axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "geology_regional_31_classes_moselle = geology_regional_31_classes_moselle[[\"area_perm_high\", \"area_perm_medium\", \"area_perm_low\"]]\n",
    "\n",
    "# Rename the columns\n",
    "geology_regional_31_classes_moselle.columns = [\"perm_high_regi\", \"perm_medium_regi\", \"perm_low_regi\"]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "geology_regional_31_classes_moselle\n",
    "\n",
    "geology_regional_31_classes_moselle[\"baseflow_index\"] = estreams_attributes[\"baseflow_index\"]\n",
    "geology_regional_31_classes_moselle.corr(method=\"pearson\")\n",
    "\n",
    "# Concatenation\n",
    "estreams_attributes[[\"perm_high_regi\", \"perm_medium_regi\", \"perm_low_regi\"]] = geology_regional_31_classes_moselle[[\"perm_high_regi\", \"perm_medium_regi\", \"perm_low_regi\"]]\n",
    "\n",
    "# Adjust the three categories for also global dataset\n",
    "estreams_attributes[\"perm_high_glob2\"] = estreams_attributes[\"perm_high_glob\"]\n",
    "estreams_attributes[\"perm_medium_glob2\"] = estreams_attributes[\"perm_medium_glob\"] + estreams_attributes[\"perm_low_glob\"]\n",
    "estreams_attributes[\"perm_low_glob2\"] = estreams_attributes[\"perm_verylow_glob\"]\n",
    "\n",
    "###########################################################################################################################\n",
    "# Adjust the columns of the dataset:\n",
    "for basin_id in estreams_attributes.index.tolist():\n",
    "\n",
    "    # Extract and divide by 100\n",
    "    v1 = estreams_attributes.loc[basin_id, \"perm_high_regi\"] / 100\n",
    "    v2 = estreams_attributes.loc[basin_id, \"perm_medium_regi\"] / 100\n",
    "    v3 = estreams_attributes.loc[basin_id, \"perm_low_regi\"] / 100\n",
    "\n",
    "    # Round all values to one decimal place\n",
    "    v1 = round(v1, 2)\n",
    "    v2 = round(v2, 2)\n",
    "    v3 = round(v3, 2)\n",
    "\n",
    "    # Ensure the sum is exactly 1 by adjusting the largest value\n",
    "    diff = 1 - (v1 + v2 + v3)\n",
    "\n",
    "    if diff != 0:\n",
    "        # Adjust the value that was the largest before rounding\n",
    "        if max(v1, v2, v3) == v1:\n",
    "            v1 += diff\n",
    "        elif max(v1, v2, v3) == v2:\n",
    "            v2 += diff\n",
    "        else:\n",
    "            v3 += diff\n",
    "\n",
    "    # Assign back\n",
    "    estreams_attributes.loc[basin_id, \"perm_high_regi\"] = v1 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_medium_regi\"] = v2 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_low_regi\"] = v3 * 100\n",
    "\n",
    "\n",
    "for basin_id in estreams_attributes.index.tolist():\n",
    "\n",
    "    # Extract and divide by 100\n",
    "    v1 = estreams_attributes.loc[basin_id, \"perm_high_glob2\"] / 100\n",
    "    v2 = estreams_attributes.loc[basin_id, \"perm_medium_glob2\"] / 100\n",
    "    v3 = estreams_attributes.loc[basin_id, \"perm_low_glob2\"] / 100\n",
    "\n",
    "    # Round all values to one decimal place\n",
    "    v1 = round(v1, 2)\n",
    "    v2 = round(v2, 2)\n",
    "    v3 = round(v3, 2)\n",
    "\n",
    "    # Ensure the sum is exactly 1 by adjusting the largest value\n",
    "    diff = 1 - (v1 + v2 + v3)\n",
    "\n",
    "    if diff != 0:\n",
    "        # Adjust the value that was the largest before rounding\n",
    "        if max(v1, v2, v3) == v1:\n",
    "            v1 += diff\n",
    "        elif max(v1, v2, v3) == v2:\n",
    "            v2 += diff\n",
    "        else:\n",
    "            v3 += diff\n",
    "\n",
    "    # Assign back\n",
    "    estreams_attributes.loc[basin_id, \"perm_high_glob2\"] = v1 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_medium_glob2\"] = v2 * 100\n",
    "    estreams_attributes.loc[basin_id, \"perm_low_glob2\"] = v3 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1bc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions\n",
    "def obj_fun_nsee(observations, simulation, expo=0.5):\n",
    "    \"\"\"\n",
    "    Calculate the Normalized Squared Error Efficiency (NSEE) while ensuring that\n",
    "    NaNs in simulation are NOT masked (only NaNs in observations are masked).\n",
    "\n",
    "    Parameters:\n",
    "        observations (array-like): Observed values (with fixed NaNs).\n",
    "        simulation (array-like): Simulated values (can contain NaNs).\n",
    "        expo (float, optional): Exponent applied to observations and simulations. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "        float: NSEE score (higher values indicate worse performance).\n",
    "    \"\"\"\n",
    "    observations = np.asarray(observations)\n",
    "    simulation = np.asarray(simulation)\n",
    "\n",
    "    # Mask only NaNs in observations\n",
    "    mask = ~np.isnan(observations)\n",
    "    obs = observations[mask]\n",
    "    sim = simulation[mask]  # Keep all simulated values, even NaNs\n",
    "\n",
    "    # If simulation contains NaNs after masking observations, return penalty\n",
    "    if np.isnan(sim).any():\n",
    "        return 10.0  # Large penalty if NaNs appear in the simulation\n",
    "\n",
    "    metric = np.sum((sim**expo - obs**expo)**2) / np.sum((obs**expo - np.mean(obs**expo))**2)\n",
    "    \n",
    "    return float(metric)\n",
    "\n",
    "\n",
    "def obj_fun_kge(observations, simulation):\n",
    "    \"\"\"\n",
    "    Calculate the KGE-2012 objective function, ensuring that NaNs in simulation are NOT masked.\n",
    "    \n",
    "    Parameters:\n",
    "        observations (array-like): Observed values (with fixed NaNs).\n",
    "        simulation (array-like): Simulated values (can contain NaNs).\n",
    "\n",
    "    Returns:\n",
    "        float: KGE-2012 score (higher values indicate worse performance).\n",
    "    \"\"\"\n",
    "    observations = np.asarray(observations)\n",
    "    simulation = np.asarray(simulation)\n",
    "\n",
    "    # Mask only NaNs in observations\n",
    "    mask = ~np.isnan(observations)\n",
    "    obs = observations[mask]\n",
    "    sim = simulation[mask]  # Keep all simulated values, even NaNs\n",
    "\n",
    "    # Check if there are NaNs in the simulation after masking obs\n",
    "    if np.isnan(sim).any():\n",
    "        return 10.0  # Large penalty if the simulation contains NaNs\n",
    "    \n",
    "    obs_mean = np.mean(obs)\n",
    "    sim_mean = np.mean(sim)\n",
    "\n",
    "    r = np.corrcoef(obs, sim)[0, 1]\n",
    "    alpha = np.std(sim) / np.std(obs)\n",
    "    beta = sim_mean / obs_mean\n",
    "\n",
    "    kge = np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)  # KGE-2012\n",
    "\n",
    "    return float(kge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define the outlet of the Moselle to be used\n",
    "outlets = [\"DEBU1959\"]\n",
    "nested_cats_df = nested_catchments.loc[outlets, :]\n",
    "\n",
    "# Now we save our dataframes in a dictionary of dataframes. One dataframe for each watershed. \n",
    "\n",
    "nested_cats_filtered = find_max_unique_rows(nested_cats_df)                                  # Filter only the catchemnts using the function stated before\n",
    "nested_cats_filtered_df = nested_catchments.loc[nested_cats_filtered, :]                     # Here we filter the catchemnts for the list (again, after we apply our function):\n",
    "\n",
    "# Store the variables for the selected catchments in a list of dataframes now for only the ones above 20 cats:\n",
    "estreams_attributes_dfs = {}\n",
    "for catchment in tqdm.tqdm(nested_cats_filtered):\n",
    "    # Retrieve the nested list of catchments for the current catchment\n",
    "    nested_clip = nested_cats_filtered_df.loc[catchment, 'nested_catchments']\n",
    "    \n",
    "    # Filter values to include only those that exist in the index of estreams_attributes\n",
    "    nested_clip = [value for value in nested_clip if value in estreams_attributes.index]\n",
    "    \n",
    "    # Filter the estreams_attributes DataFrame based on the filtered nested_clip\n",
    "    cat_clip = estreams_attributes.loc[nested_clip, :]\n",
    "    \n",
    "    # Store the resulting DataFrame in the dictionary\n",
    "    estreams_attributes_dfs[catchment] = cat_clip\n",
    "\n",
    "# Here we can save the length of each watershed (number of nested catchemnts)\n",
    "catchment_lens = pd.DataFrame(index = estreams_attributes_dfs.keys())\n",
    "for catchment, data in estreams_attributes_dfs.items():\n",
    "    catchment_lens.loc[catchment, \"len\"] = len(data)\n",
    "\n",
    "# Now we can filter it properly:\n",
    "nested_cats_filtered_abovevalue = catchment_lens[catchment_lens.len >= 10]\n",
    "\n",
    "# # Here we filter the catchemnts for the list (again, after we apply our function):\n",
    "nested_cats_filtered_abovevalue_df = nested_catchments.loc[nested_cats_filtered_abovevalue.index, :]\n",
    "\n",
    "# Store the variables for the selected catchments in a list of dataframes now for only the ones above 20 cats:\n",
    "estreams_attributes_dfs = {}\n",
    "\n",
    "for catchment in tqdm.tqdm(nested_cats_filtered_abovevalue_df.index):\n",
    "    # Retrieve the nested list of catchments for the current catchment\n",
    "    nested_clip = nested_cats_filtered_abovevalue_df.loc[catchment, 'nested_catchments']\n",
    "    \n",
    "    # Filter values to include only those that exist in the index of estreams_attributes\n",
    "    nested_clip = [value for value in nested_clip if value in estreams_attributes.index]\n",
    "    \n",
    "    # Filter the estreams_attributes DataFrame based on the filtered nested_clip\n",
    "    cat_clip = estreams_attributes.loc[nested_clip, :]\n",
    "    \n",
    "    # Store the resulting DataFrame in the dictionary\n",
    "    estreams_attributes_dfs[catchment] = cat_clip\n",
    "\n",
    "# Adjust and clip it:\n",
    "estreams_attributes_clipped = estreams_attributes_dfs[\"DEBU1959\"]\n",
    "\n",
    "# Convert 'date_column' and 'time_column' to datetime\n",
    "estreams_attributes_clipped['start_date'] = pd.to_datetime(estreams_attributes_clipped['start_date'])\n",
    "estreams_attributes_clipped['end_date'] = pd.to_datetime(estreams_attributes_clipped['end_date'])\n",
    "\n",
    "\n",
    "estreams_attributes_clipped_filters = estreams_attributes_clipped[estreams_attributes_clipped.end_date >= \"2010\"]\n",
    "estreams_attributes_clipped_filters = estreams_attributes_clipped_filters[estreams_attributes_clipped_filters.start_date <= \"2002\"]\n",
    "\n",
    "# Here we retrieve the conectivity (from EStreams computation)\n",
    "# Load the nested catchments CSV file\n",
    "df = pd.read_excel(\"../data/nested_catchments.xlsx\")\n",
    "\n",
    "# Rename columns for clarity\n",
    "df = df.rename(columns={df.columns[1]: \"basin_id\", df.columns[2]: \"connected_basin_id\"})\n",
    "df = df.drop(columns=[df.columns[0]])  # Drop the unnamed index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments_ids = [\"FR003237\", # Epinal\n",
    "                    \"FR003249\", # Toul\n",
    "                    \"FR003253\", # Luneville\n",
    "                    \"FR000159\", # Malzeville \n",
    "                    \"FR003265\", # Custines\n",
    "                    \"FR003271\", # Nomeny\n",
    "                    \"FR000171\", # Metz\n",
    "                    \"FR003272\", # Hanconcourt\n",
    "                    \"FR003283\", # Rosselange\n",
    "                    \"FR003275\", # Boncourt\n",
    "                    \"DEBU1956\", # Perl\n",
    "                    \"DEBU1957\", #Fremersdorf\n",
    "                    \"FR003308\", #Niedaltdorf\n",
    "                    \"FR003301\", # Wittring\n",
    "                    \"FR003304\", # Bliesbruck\n",
    "                    \"LU000007\", #Ettelbruck\n",
    "                    \"DERP2004\", # GemuendOur\n",
    "                    \"DERP2017\", # Hentern\n",
    "                    \"DEBU1958\", # Trier\n",
    "                    \"DERP2024\", # Kordel\n",
    "                    \"DERP2033\", # Plein\n",
    "                    \"DEBU1959\", # Cochem\n",
    "                    \"DERP2011\", #Alsdorf \n",
    "                    \"DERP2003\", # Bollendorf\n",
    "                    \"DERP2007\"] # Pruem\n",
    "\n",
    "catchments_ids = [\"FR003237\", # Epinal\n",
    "                    \"FR003249\", # Toul\n",
    "                    \"FR000159\", # Malzeville \n",
    "                    \"FR003265\", # Custines\n",
    "                    \"FR000171\", # Metz\n",
    "                    \"FR003275\", # Boncourt\n",
    "                    \"DEBU1956\", # Perl\n",
    "                    \"FR003301\", # Wittring\n",
    "                    \"LU000007\", #Ettelbruck\n",
    "                    \"DERP2004\", # GemuendOur\n",
    "                    \"DERP2024\", # Kordel\n",
    "                    \"DEBU1959\", # Cochem\n",
    "                    \"DERP2011\"] #Alsdorf \n",
    "\n",
    "catchments_ids = [\"DEBU1958\", # Trier                    \n",
    "                  \"FR003272\", # Hanconcourt\n",
    "                  \"DEBU1957\", # Fremersdorf\n",
    "                  \"DERP2003\", # Bollendorf\n",
    "                  \"FR003308\", # Niedaltdorf\n",
    "                  \"FR003283\", # Rosselange\n",
    "                  \"FR003253\", # Luneville\n",
    "                  \"FR003271\", # Nomeny\n",
    "                  \"DERP2033\", # Plein\n",
    "                  \"DERP2017\", # Hentern\n",
    "                  \"FR003304\", # Bliesbruck\n",
    "                  \"DERP2007\"] # Pruem\n",
    "\n",
    "# Catchments used in the original Moselle paper (only)\n",
    "catchments_ids = [\"FR003237\", # Epinal\n",
    "                    \"FR003249\", # Toul\n",
    "                    \"FR003253\", # Luneville\n",
    "                    \"FR000159\", # Malzeville \n",
    "                    \"FR003265\", # Custines\n",
    "                    \"FR003271\", # Nomeny\n",
    "                    \"FR000171\", # Metz\n",
    "                    \"FR003272\", # Hanconcourt\n",
    "                    \"FR003283\", # Rosselange\n",
    "                    \"FR003275\", # Boncourt\n",
    "                    \"DEBU1956\", # Perl\n",
    "                    \"DEBU1957\", #Fremersdorf\n",
    "                    \"FR003308\", #Niedaltdorf\n",
    "                    \"FR003301\", # Wittring\n",
    "                    #\"FR003304\", # Bliesbruck\n",
    "                    \"LU000007\", #Ettelbruck\n",
    "                    \"DERP2004\", # GemuendOur\n",
    "                    \"DERP2017\", # Hentern\n",
    "                    \"DEBU1958\", # Trier\n",
    "                    \"DERP2024\", # Kordel\n",
    "                    \"DERP2033\", # Plein\n",
    "                    \"DEBU1959\", # Cochem\n",
    "                    \"DERP2011\", #Alsdorf \n",
    "                    \"DERP2003\", # Bollendorf\n",
    "                    \"DERP2007\"] # Pruem\n",
    "# Nalbach MISSING\n",
    "# Reinheim MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49acccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot start_date and end_date on the same graph\n",
    "estreams_attributes_clipped_filters.start_date.plot(ax=ax, label=\"Start Date\")\n",
    "estreams_attributes_clipped_filters.end_date.plot(ax=ax, label=\"End Date\")\n",
    "\n",
    "# Make y-axis label vertical\n",
    "ax.set_ylabel(\"Date\", rotation=90)\n",
    "\n",
    "# Ensure ALL x-axis ticks are shown\n",
    "ax.set_xticks(np.arange(len(estreams_attributes_clipped_filters)))  # Set all x-ticks\n",
    "ax.set_xticklabels(estreams_attributes_clipped_filters.index, rotation=90)  # Rotate labels\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catchments_ids = estreams_attributes_clipped_filters.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d22d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "estreams_attributes_clipped_filters_to_be_sorted = estreams_attributes.loc[catchments_ids, :]\n",
    "\n",
    "# At this part we sort the values in order according to the area, and select the second as done in the Moselle paper originally. \n",
    "# Sort the DataFrame by 'area_estreams'\n",
    "estreams_attributes_clipped_sorted = estreams_attributes_clipped_filters_to_be_sorted.sort_values(by='area_estreams')\n",
    "\n",
    "# Select every second value (even index positions)\n",
    "first_half_df = estreams_attributes_clipped_sorted.iloc[::2]\n",
    "\n",
    "# Select the alternating second values (odd index positions)\n",
    "second_half_df = estreams_attributes_clipped_sorted.iloc[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half_df = ['FR000184',\n",
    " 'DERP2017',\n",
    " 'DERP2011',\n",
    " 'DERP2013',\n",
    " 'DERP2007',\n",
    " 'DERP2024',\n",
    " 'FR003253',\n",
    " 'FR003308',\n",
    " 'FR003283',\n",
    " 'FR003301',\n",
    " 'DERP2003',\n",
    " 'FR003265',\n",
    " 'FR003272',\n",
    " 'DEBU1958']\n",
    "\n",
    "\n",
    "\n",
    "second_half_df = ['FR003303',\n",
    " 'FR000144',\n",
    " 'DERP2033',\n",
    " 'FR003275',\n",
    " 'DERP2004',\n",
    " 'FR003271',\n",
    " 'LU000007',\n",
    " 'FR003237',\n",
    " 'FR000171',\n",
    " 'FR000159',\n",
    " 'FR003249',\n",
    " 'DEBU1957',\n",
    " 'DEBU1956',\n",
    " 'DEBU1959']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd16060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catchments_ids = first_half_df.index.tolist()\n",
    "catchments_ids = first_half_df\n",
    "\n",
    "#catchments_ids = second_half_df.index.tolist()\n",
    "#catchments_ids = estreams_attributes_clipped_sorted.index.tolist()\n",
    "\n",
    "# Run the iterative function\n",
    "iterative_immediate_downstream = find_iterative_immediate_downstream(df, catchments_ids)\n",
    "\n",
    "# Convert results to a DataFrame for display\n",
    "iterative_downstream_df = pd.DataFrame(iterative_immediate_downstream.items(), \n",
    "                                       columns=['basin_id', 'immediate_downstream_basin'])\n",
    "\n",
    "\n",
    "# Assuming the DataFrame has columns 'basin_id' and 'downstream_id'\n",
    "topology_list = {basin: None for basin in catchments_ids}  # Default to None\n",
    "\n",
    "# Filter DataFrame for relevant basin_ids and update topology\n",
    "for _, row in iterative_downstream_df.iterrows():\n",
    "    if row['basin_id'] in topology_list:\n",
    "        topology_list[row['basin_id']] = row['immediate_downstream_basin']\n",
    "\n",
    "topology_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a482001",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inputs = r'C:\\Users\\nascimth\\Documents\\Thiago\\Eawag\\Python\\Scripts\\estreams_superflexpy\\data\\models\\input\\subset_2001_2015'\n",
    "\n",
    "inputs = np.load(path_inputs+'\\\\inputs.npy', allow_pickle=True).item()\n",
    "observations = np.load(path_inputs+'\\\\observations.npy', allow_pickle=True).item()\n",
    "areas = np.load(path_inputs+'\\\\areas.npy', allow_pickle=True).item()\n",
    "perm_areas = np.load(path_inputs+'\\\\perm_areas.npy', allow_pickle=True).item()\n",
    "perm_areasglobal = np.load(path_inputs+'\\\\perm_areasglobal.npy', allow_pickle=True).item()\n",
    "quality_masks = np.load(path_inputs+'\\\\quality_masks.npy', allow_pickle=True).item()\n",
    "rootdepth_mean = np.load(path_inputs+'\\\\rootdepth_mean.npy', allow_pickle=True).item()\n",
    "waterdeficit_mean = np.load(path_inputs+'\\\\waterdeficit_mean.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb7441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e10dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf65a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf25768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ceaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5bfee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52343368",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_finder = PegasusNumba()\n",
    "num_app = ImplicitEulerNumba(root_finder=root_finder)\n",
    "\n",
    "class ParameterizedSingleFluxSplitter(ParameterizedElement):\n",
    "    _num_downstream = 2\n",
    "    _num_upstream = 1\n",
    "    \n",
    "    def set_input(self, input):\n",
    "\n",
    "        self.input = {'Q_in': input[0]}\n",
    "\n",
    "    def get_output(self, solve=True):\n",
    "\n",
    "        split_par = self._parameters[self._prefix_parameters + 'splitpar']\n",
    "\n",
    "        output1 = [self.input['Q_in'] * split_par]\n",
    "        output2 = [self.input['Q_in'] * (1 - split_par)]\n",
    "        \n",
    "        return [output1, output2]   \n",
    "    \n",
    "    \n",
    "lower_splitter = ParameterizedSingleFluxSplitter(\n",
    "    parameters={'splitpar': 0.5},\n",
    "    id='lowersplitter'\n",
    ")\n",
    "\n",
    "lower_splitter_medium = ParameterizedSingleFluxSplitter(\n",
    "    parameters={'splitpar': 0.6},\n",
    "    id='lowersplitter'\n",
    ")\n",
    "\n",
    "lower_splitter_high = ParameterizedSingleFluxSplitter(\n",
    "    parameters={'splitpar': 0.7},\n",
    "    id='lowersplitter'\n",
    ")\n",
    "\n",
    "# Fluxes in the order P, T, PET\n",
    "upper_splitter = Splitter(\n",
    "    direction=[\n",
    "        [0, 1, None],    # P and T go to the snow reservoir\n",
    "        [2, None, None]  # PET goes to the transparent element\n",
    "    ],\n",
    "    weight=[\n",
    "        [1.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ],\n",
    "    id='upper-splitter'\n",
    ")\n",
    "\n",
    "snow = SnowReservoir(\n",
    "    parameters={'t0': 0.0, 'k': 0.01, 'm': 2.0},\n",
    "    states={'S0': 0.0},\n",
    "    approximation=num_app,\n",
    "    id='snow'\n",
    ")\n",
    "\n",
    "upper_transparent = Transparent(\n",
    "    id='upper-transparent'\n",
    ")\n",
    "\n",
    "upper_junction = Junction(\n",
    "    direction=[\n",
    "        [0, None],\n",
    "        [None, 0]\n",
    "    ],\n",
    "    id='upper-junction'\n",
    ")\n",
    "\n",
    "\n",
    "unsaturated = UnsaturatedReservoir(\n",
    "    parameters={'Smax': 150.0, 'Ce': 1.0, 'm': 0.01, 'beta': 2.0},\n",
    "    states={'S0': 10.0},\n",
    "    approximation=num_app,\n",
    "    id='unsaturated'\n",
    ")\n",
    "\n",
    "fast = PowerReservoir(\n",
    "    parameters={'k': 0.01, 'alpha': 2.0},\n",
    "    states={'S0': 0.0},\n",
    "    approximation=num_app,\n",
    "    id='fast'\n",
    ")\n",
    "\n",
    "slow = PowerReservoir(\n",
    "    parameters={'k': 1e-4, 'alpha': 1.0},\n",
    "    states={'S0': 0.0},\n",
    "    approximation=num_app,\n",
    "    id='slow'\n",
    ")\n",
    "\n",
    "slowhigh = PowerReservoir(\n",
    "    parameters={'k': 1e-4, 'alpha': 2.0},\n",
    "    states={'S0': 0.0},\n",
    "    approximation=num_app,\n",
    "    id='slowhigh'\n",
    ")\n",
    "\n",
    "\n",
    "lower_junction = Junction(\n",
    "    direction=[\n",
    "        [0, 0]\n",
    "    ],\n",
    "    id='lower-junction'\n",
    ")\n",
    "\n",
    "lag_fun = HalfTriangularLag(\n",
    "    parameters={'lag-time': 4.0},\n",
    "    states={'lag': None},\n",
    "    id='lag-fun'\n",
    ")\n",
    "\n",
    "lower_transparent = Transparent(\n",
    "    id='lower-transparent'\n",
    ")\n",
    "\n",
    "lower_transparent2 = Transparent(\n",
    "    id='lower-transparent2'\n",
    ")\n",
    "\n",
    "general = Unit(\n",
    "    layers=[\n",
    "        [upper_splitter],\n",
    "        [snow, upper_transparent],\n",
    "        [upper_junction],\n",
    "        [unsaturated],\n",
    "        [lower_splitter],\n",
    "        [slow, lag_fun],\n",
    "        [lower_transparent, fast],\n",
    "        [lower_junction],\n",
    "    ],\n",
    "    id='general'\n",
    ")\n",
    "\n",
    "low = Unit(\n",
    "    layers=[\n",
    "        [upper_splitter],\n",
    "        [snow, upper_transparent],\n",
    "        [upper_junction],\n",
    "        [unsaturated],\n",
    "        [fast],\n",
    "    ],\n",
    "    id='low'\n",
    ")\n",
    "\n",
    "high = Unit(\n",
    "    layers=[\n",
    "        [upper_splitter],\n",
    "        [snow, upper_transparent],\n",
    "        [upper_junction],\n",
    "        [unsaturated],\n",
    "        [slowhigh],\n",
    "    ],\n",
    "    id='high'\n",
    ")\n",
    "\n",
    "\n",
    "# Generate Nodes dynamically and assign them as global variables\n",
    "catchments = [] # Dictionary to store nodes\n",
    "\n",
    "for cat_id in catchments_ids:\n",
    "    node = Node(\n",
    "        units=[high, general, low],  # Use unit from dictionary or default\n",
    "        weights=perm_areasglobal[cat_id],\n",
    "        area=areas.get(cat_id),  # Use predefined area or default\n",
    "        id=cat_id\n",
    "    )\n",
    "    catchments.append(node)  # Store in the list\n",
    "\n",
    "    # Assign the node as a global variable\n",
    "    globals()[cat_id] = node\n",
    "\n",
    "# Ensure topology only includes nodes that exist in `catchments_ids`\n",
    "topology = {\n",
    "    cat_id: upstream if upstream in catchments_ids else None\n",
    "    for cat_id, upstream in topology_list.items() if cat_id in catchments_ids\n",
    "}\n",
    "\n",
    "# Create the Network\n",
    "model = Network(\n",
    "    nodes=catchments,  # Pass list of Node objects\n",
    "    topology=topology  \n",
    ")\n",
    "\n",
    "\n",
    "# Set inputs for each node using the manually defined dictionary\n",
    "for cat in catchments:\n",
    "    cat.set_input(inputs[cat.id])  # Correct way to set inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05d012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ab706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_parameter_values(parameters_name_model, parameter_names, parameters):\n",
    "    \"\"\"\n",
    "    Assigns values from `parameters` to `parameters_name_model` where a match exists in `parameter_names`,\n",
    "    but keeps any parameters that have three segments (`X_Y_Z`) unchanged.\n",
    "\n",
    "    Args:\n",
    "        parameters_name_model (list): List of full parameter names (e.g., \"general_slow_k\").\n",
    "        parameter_names (list): List of unique parameter names (e.g., \"slow_k\", \"high_slow_k\").\n",
    "        parameters (list): List of values corresponding to `parameter_names`.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary {parameter_name_model: assigned_value}, where:\n",
    "            - `X_Y` parameters are updated from `parameter_names`.\n",
    "            - `X_Y_Z` parameters are kept unchanged.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping parameter_names to their corresponding values\n",
    "    param_value_dict = {param_name: value for param_name, value in zip(parameter_names, parameters)}\n",
    "\n",
    "    # Build the output dictionary\n",
    "    filtered_parameters = {}\n",
    "\n",
    "    for param_name in parameters_name_model:\n",
    "        parts = param_name.split(\"_\")  # Split the name to check structure\n",
    "        base_name = \"_\".join(parts[-2:])  # Extract last two parts (X_Y)\n",
    "        \n",
    "        if base_name in param_value_dict:  # If X_Y is in parameter_names\n",
    "            filtered_parameters[param_name] = param_value_dict[base_name]\n",
    "        elif param_name in parameter_names:  # Direct match in parameter_names (X_Y)\n",
    "            filtered_parameters[param_name] = param_value_dict[param_name]\n",
    "    \n",
    "    return filtered_parameters  # Return dictionary of matched parameters\n",
    "\n",
    "\n",
    "class spotpy_model(object):\n",
    "\n",
    "    def __init__(self, model, catchments, dt, observations, parameters, parameter_names, parameter_names_model, output_index, warm_up=365):\n",
    "\n",
    "        \"\"\"\n",
    "        Spotpy model for multi-node calibration in SuperflexPy.\n",
    "\n",
    "        Args:\n",
    "            model (Network): SuperflexPy network containing multiple nodes.\n",
    "            catchments (list): List of Node objects.\n",
    "            inputs (dict): Dictionary with inputs for each node.\n",
    "            dt (float): Time step.\n",
    "            observations (dict): Observed discharge data for each node.\n",
    "            parameters (list): List of parameter distributions for calibration.\n",
    "            parameter_names (list): Names of the parameters.\n",
    "            output_index (str/int): The output key for extracting model results.\n",
    "            warm_up (int): Number of time steps to ignore in the evaluation.\n",
    "        \"\"\"\n",
    "        self._model = model  # The SuperflexPy network\n",
    "        self._catchments = catchments  # List of catchments\n",
    "        self._dt = dt  # Time step\n",
    "\n",
    "        # Store shared calibration parameters\n",
    "        self._parameters = parameters\n",
    "        self._parameter_names = parameter_names\n",
    "        self._parameter_names_model = parameter_names_model  # Store full parameter names\n",
    "\n",
    "        # Store inputs and observations for each node\n",
    "        self._observations = observations  # Dictionary {node_id: observed_data}\n",
    "        self._output_index = output_index  # Output key (e.g., 'Q_out')\n",
    "        self._warm_up = int(warm_up)  # Warm-up period\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Generate parameter samples for calibration.\"\"\"\n",
    "        return spotpy.parameter.generate(self._parameters)\n",
    "\n",
    "    def simulation(self, parameters):\n",
    "        \"\"\"Runs the entire network using the same parameter set and collects per-node outputs.\"\"\"\n",
    "\n",
    "        # Convert parameter list into a dictionary\n",
    "        #named_parameters = assign_parameter_values(self._parameter_names_model, self._parameter_names, parameters)\n",
    "        \n",
    "        # Check if parameters have changed (avoid unnecessary computations)\n",
    "        if not hasattr(self, \"_cached_params\") or not np.array_equal(self._cached_params, parameters):\n",
    "            self._cached_params = np.array(parameters)  # Store the current parameters\n",
    "            named_parameters = assign_parameter_values(self._parameter_names_model, self._parameter_names, parameters)\n",
    "            self._model.set_parameters(named_parameters)  # Apply shared parameters\n",
    "\n",
    "        # Ensure `named_parameters` is always defined\n",
    "        #named_parameters = None  \n",
    "\n",
    "        ## Check if parameters have changed (avoid unnecessary computations)\n",
    "        #if not hasattr(self, \"_cached_params\") or not np.array_equal(self._cached_params, parameters):\n",
    "        #    self._cached_params = np.array(parameters)  # Store the current parameters\n",
    "        #    named_parameters = assign_parameter_values(self._parameter_names_model, self._parameter_names, parameters)\n",
    "        #    self._cached_named_parameters = named_parameters  # Cache the named parameters\n",
    "        #    self._model.set_parameters(named_parameters)  # Apply shared parameters\n",
    "        #else:\n",
    "        #    named_parameters = self._cached_named_parameters  # Retrieve from cache\n",
    "\n",
    "        # Apply shared parameters to the whole network\n",
    "        self._model.set_parameters(named_parameters)\n",
    "\n",
    "        # Set timestep and reset the network\n",
    "        self._model.set_timestep(self._dt)\n",
    "        self._model.reset_states()\n",
    "\n",
    "        # Run the full network\n",
    "        output = self._model.get_output()  # Get outputs for all nodes\n",
    "\n",
    "        # Return outputs as a list (one per node)\n",
    "        return [output[cat.id][self._output_index] for cat in self._catchments]\n",
    "\n",
    "    def evaluation(self):\n",
    "        \"\"\"Returns the observed data for all nodes.\"\"\"\n",
    "        return self._observations\n",
    "\n",
    "    def objectivefunction(self, simulation, evaluation):\n",
    "        \"\"\"Computes the average NSE (or another metric) across all nodes.\"\"\"\n",
    "\n",
    "        obj_values = []  # Store individual NSE values for each node\n",
    "\n",
    "        for sim, cat in zip(simulation, self._catchments):\n",
    "            node_id = cat.id\n",
    "            obs = evaluation[node_id]\n",
    "\n",
    "            # Apply warm-up period\n",
    "            sim = sim[self._warm_up + 1:]\n",
    "            obs = obs[self._warm_up + 1:]\n",
    "\n",
    "            # Compute NSE (or another metric like KGE)\n",
    "            obj_value = obj_fun_nsee(observations=obs, simulation=sim, expo=0.5)\n",
    "            obj_values.append(obj_value)\n",
    "\n",
    "        # Compute the average objective function across all nodes\n",
    "        return np.mean(obj_values)  # Minimize the average error\n",
    "\n",
    "model.reset_states()\n",
    "\n",
    "spotpy_hyd_mod = spotpy_model(\n",
    "    model=model,  # The entire SuperflexPy network\n",
    "    catchments=catchments,  # Use predefined catchments list\n",
    "    dt=1.0,  # Time step\n",
    "    observations=observations,  # Observed data per node\n",
    "    parameters=[\n",
    "        spotpy.parameter.Uniform(\"general_fast_k\", 0.0001, 1.0), #1e-5, 1.0\n",
    "        spotpy.parameter.Uniform(\"low_fast_k\", 0.0001, 1.0),\n",
    "\n",
    "        spotpy.parameter.Uniform(\"high_slowhigh_k\", 1e-7, 0.1),\n",
    "        spotpy.parameter.Uniform(\"general_slow_k\", 1e-7, 0.1),\n",
    "\n",
    "        spotpy.parameter.Uniform(\"unsaturated_Ce\", 0.1, 3.0),\n",
    "        spotpy.parameter.Uniform(\"snow_k\", 0.01, 10.0),\n",
    "        spotpy.parameter.Uniform(\"unsaturated_Smax\", 100.0, 600.0),\n",
    "        spotpy.parameter.Uniform(\"splitpar\", 0.5, 0.9),\n",
    "        spotpy.parameter.Uniform(\"unsaturated_beta\", 0.01, 10.0),\n",
    "        spotpy.parameter.Uniform(\"lag-fun_lag-time\", 1.0, 10.0),\n",
    "    ],\n",
    "    parameter_names=[\n",
    "        \"general_fast_k\", \"low_fast_k\", \n",
    "        \"high_slowhigh_k\", \"general_slow_k\", \"unsaturated_Ce\", \"snow_k\", \"unsaturated_Smax\", \"splitpar\",\n",
    "        \"unsaturated_beta\", \"lag-fun_lag-time\",\n",
    "    ],\n",
    "    parameter_names_model = model.get_parameters_name(),\n",
    "    output_index=0,  # Assumes all nodes have the same output variable\n",
    "    warm_up=365  # Warm-up period\n",
    ")\n",
    "\n",
    "#parameter_names_model = model.get_parameters_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = spotpy.algorithms.sceua(spotpy_hyd_mod, dbname=None, dbformat='ram')\n",
    "sampler = spotpy.algorithms.sceua(spotpy_hyd_mod, dbname='calibration', dbformat=\"csv\", parallel=\"seq\")\n",
    "\n",
    "sampler.sample(repetitions=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46493f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "results_df = pd.read_csv(\"calibration.csv\")\n",
    "\n",
    "\n",
    "# Convert to a NumPy structured array (similar to `sampler.getdata()`)\n",
    "results = results_df.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c35573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = sampler.getdata()                                                  # Load the results\n",
    "spotpy.analyser.plot_parametertrace(results)                                 # Show the results\n",
    "\n",
    "\n",
    "bestindex, bestobjf = spotpy.analyser.get_minlikeindex(results)               # Get the best indexes and objective function\n",
    "\n",
    "\n",
    "spotpy.analyser.get_parameters(results)[bestindex]\n",
    "\n",
    "best_params_dict = dict(zip(spotpy.analyser.get_parameternames(results), spotpy.analyser.get_parameters(results)[bestindex]))\n",
    "\n",
    "\n",
    "if 'splitpar' in best_params_dict:\n",
    "    best_params_dict['general_lowersplitter_splitpar'] = best_params_dict.pop('splitpar')\n",
    "\n",
    "if 'M4_lagfun_lagtime' in best_params_dict:\n",
    "    best_params_dict['M4_lag-fun_lag-time'] = best_params_dict.pop('M4_lagfun_lagtime')\n",
    "\n",
    "\n",
    "# Remove spaces and replace with underscores (or any other transformation)\n",
    "best_params_dict = {key.replace(\" \", \"\"): value for key, value in best_params_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b800739",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8becece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names = list(best_params_dict.keys())\n",
    "parameters = list(best_params_dict.values())\n",
    "parameter_names_model = model.get_parameters_name()\n",
    "best_params_dict_model = assign_parameter_values(parameter_names_model, parameter_names, parameters)\n",
    "best_params_dict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638942a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict_model_r_1 = {'high_snow_k': 4.086426297944429,\n",
    " 'high_unsaturated_Ce': 0.9567288089362507,\n",
    " 'high_unsaturated_beta': 1.0331337523819135,\n",
    " 'high_slowhigh_k': 0.0013319218103794586,\n",
    " 'general_snow_k': 4.086426297944429,\n",
    " 'general_unsaturated_Ce': 0.9567288089362507,\n",
    " 'general_unsaturated_beta': 1.0331337523819135,\n",
    " 'general_slow_k': 0.011234798028853129,\n",
    " 'general_lag-fun_lag-time': 3.9750011064022424,\n",
    " 'general_fast_k': 0.48590540089635903,\n",
    " 'low_snow_k': 4.086426297944429,\n",
    " 'low_unsaturated_Ce': 0.9567288089362507,\n",
    " 'low_unsaturated_beta': 1.0331337523819135,\n",
    " 'low_fast_k': 0.004905033249936297}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict_model_g_1 = {'high_snow_k': 4.196749756267835,\n",
    " 'high_unsaturated_Ce': 0.8669048058401205,\n",
    " 'high_unsaturated_beta': 0.8923904812427841,\n",
    " 'high_slowhigh_k': 0.0009871387474522922,\n",
    " 'general_snow_k': 4.196749756267835,\n",
    " 'general_unsaturated_Ce': 0.8669048058401205,\n",
    " 'general_unsaturated_beta': 0.8923904812427841,\n",
    " 'general_slow_k': 0.024640353857886783,\n",
    " 'general_lag-fun_lag-time': 3.175523750291455,\n",
    " 'general_fast_k': 0.25928255610147044,\n",
    " 'low_snow_k': 4.196749756267835,\n",
    " 'low_unsaturated_Ce': 0.8669048058401205,\n",
    " 'low_unsaturated_beta': 0.8923904812427841,\n",
    " 'low_fast_k': 0.16955621942568638}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict_model_r_1_Sumax = {'high_snow_k': 4.827621,\n",
    " 'high_unsaturated_Smax': 135.82315,\n",
    " 'high_unsaturated_Ce': 0.7436071,\n",
    " 'high_unsaturated_beta': 1.3400413,\n",
    " 'high_slowhigh_k': 0.00022118725,\n",
    " 'general_snow_k': 4.827621,\n",
    " 'general_unsaturated_Smax': 135.82315,\n",
    " 'general_unsaturated_Ce': 0.7436071,\n",
    " 'general_unsaturated_beta': 1.3400413,\n",
    " 'general_slow_k': 0.04206265,\n",
    " 'general_lag-fun_lag-time': 3.6903367,\n",
    " 'general_fast_k': 0.48363513,\n",
    " 'low_snow_k': 4.827621,\n",
    " 'low_unsaturated_Smax': 135.82315,\n",
    " 'low_unsaturated_Ce': 0.7436071,\n",
    " 'low_unsaturated_beta': 1.3400413,\n",
    " 'low_fast_k': 0.0070152953}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict_model_r_1_SumaxD = {'high_snow_k': 2.8131618,\n",
    " 'high_unsaturated_Smax': 115.87451,\n",
    " 'high_unsaturated_Ce': 0.77449185,\n",
    " 'high_unsaturated_beta': 1.6093758,\n",
    " 'high_slowhigh_k': 3.0406694e-05,\n",
    " 'general_snow_k': 2.8131618,\n",
    " 'general_unsaturated_Smax': 115.87451,\n",
    " 'general_unsaturated_Ce': 0.77449185,\n",
    " 'general_unsaturated_beta': 1.6093758,\n",
    " 'general_lowersplitter_splitpar': 0.7289779,\n",
    " 'general_slow_k': 0.07241783,\n",
    " 'general_lag-fun_lag-time': 3.040764,\n",
    " 'general_fast_k': 0.14148608,\n",
    " 'low_snow_k': 2.8131618,\n",
    " 'low_unsaturated_Smax': 115.87451,\n",
    " 'low_unsaturated_Ce': 0.77449185,\n",
    " 'low_unsaturated_beta': 1.6093758,\n",
    " 'low_fast_k': 0.0048795976}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict_model_g_1_SumaxD = {'high_snow_k': 2.934993580860046,\n",
    " 'high_unsaturated_Smax': 127.23002055688586,\n",
    " 'high_unsaturated_Ce': 0.8032976193402295,\n",
    " 'high_unsaturated_beta': 1.2176739587191074,\n",
    " 'high_slowhigh_k': 3.0406694e-05,\n",
    " 'general_snow_k': 2.934993580860046,\n",
    " 'general_unsaturated_Smax': 127.23002055688586,\n",
    " 'general_unsaturated_Ce': 0.8032976193402295,\n",
    " 'general_unsaturated_beta': 1.2176739587191074,\n",
    " 'general_lowersplitter_splitpar': 0.7510347309521164,\n",
    " 'general_slow_k': 0.09993578628220479,\n",
    " 'general_lag-fun_lag-time': 2.8801273144273436,\n",
    " 'general_fast_k': 0.12130750321170947,\n",
    " 'low_snow_k': 2.934993580860046,\n",
    " 'low_unsaturated_Smax': 127.23002055688586,\n",
    " 'low_unsaturated_Ce': 0.8032976193402295,\n",
    " 'low_unsaturated_beta': 1.2176739587191074,\n",
    " 'low_fast_k': 0.0016403798882305785}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8527d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict_model = best_params_dict_model_g_1_SumaxD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3267a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()\n",
    "\n",
    "# Set inputs for each node using the manually defined dictionary\n",
    "for cat in catchments:\n",
    "    cat.set_input(inputs[cat.id])  # Correct way to set inputs\n",
    "\n",
    "model.set_timestep(1.0)\n",
    "\n",
    "model.set_parameters(best_params_dict_model)\n",
    "\n",
    "#hyd_mod.reset_states()\n",
    "output = model.get_output()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87566b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_cal_g_1_56 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_cal_g_1_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2001-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_cal_g_1_56 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_cal_g_1_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_g_1_56.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_cal_r_1_56 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_cal_r_1_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ae38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_cal_g_1 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_cal_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_cal_g_1 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_cal_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01001a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_cal_r_1 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_cal_r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ea120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_cal_r_1 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_cal_r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e025645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_cal_r_1 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_cal_r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_r_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "plt.scatter(nse_results_cal_r_1[\"bfi_obs\"], nse_results_cal_r_1[\"bfi_sim\"], alpha=0.6)\n",
    "# Set limits (adjust according to your data range)\n",
    "plt.xlim([0.2, 1])\n",
    "plt.ylim([0.2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bf0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "plt.scatter(nse_results_cal_g_1_56[\"bfi_obs\"], nse_results_cal_g_1_56[\"bfi_sim\"], alpha=0.6)\n",
    "# Set limits (adjust according to your data range)\n",
    "plt.xlim([0.2, 1])\n",
    "plt.ylim([0.2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4606c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(nse_results_cal_r_1[\"q_mean_obs\"], nse_results_cal_r_1[\"q_mean_calc\"], alpha=0.6)\n",
    "# Set limits (adjust according to your data range)\n",
    "#plt.xlim([0.2, 1])\n",
    "#plt.ylim([0.2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydroanalysis as hydroanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe71b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086eae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81e962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inputs = r'C:\\Users\\nascimth\\Documents\\Thiago\\Eawag\\Python\\Scripts\\estreams_superflexpy\\data\\models\\input\\subset_2001_2015'\n",
    "\n",
    "inputs = np.load(path_inputs+'\\\\inputs.npy', allow_pickle=True).item()\n",
    "observations = np.load(path_inputs+'\\\\observations.npy', allow_pickle=True).item()\n",
    "areas = np.load(path_inputs+'\\\\areas.npy', allow_pickle=True).item()\n",
    "perm_areas = np.load(path_inputs+'\\\\perm_areas.npy', allow_pickle=True).item()\n",
    "quality_masks = np.load(path_inputs+'\\\\quality_masks.npy', allow_pickle=True).item()\n",
    "rootdepth_mean = np.load(path_inputs+'\\\\rootdepth_mean.npy', allow_pickle=True).item()\n",
    "waterdeficit_mean= np.load(path_inputs+'\\\\waterdeficit_mean.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inputs = r'C:\\Users\\nascimth\\Documents\\Thiago\\Eawag\\Python\\Scripts\\estreams_superflexpy\\data\\models\\input\\subset_1988_2001'\n",
    "\n",
    "inputs = np.load(path_inputs+'\\\\inputs.npy', allow_pickle=True).item()\n",
    "observations = np.load(path_inputs+'\\\\observations.npy', allow_pickle=True).item()\n",
    "areas = np.load(path_inputs+'\\\\areas.npy', allow_pickle=True).item()\n",
    "perm_areas = np.load(path_inputs+'\\\\perm_areas.npy', allow_pickle=True).item()\n",
    "quality_masks = np.load(path_inputs+'\\\\quality_masks.npy', allow_pickle=True).item()\n",
    "rootdepth_mean = np.load(path_inputs+'\\\\rootdepth_mean.npy', allow_pickle=True).item()\n",
    "waterdeficit_mean= np.load(path_inputs+'\\\\waterdeficit_mean.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d85b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_areasglobal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d017354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catchments_ids = second_half_df.index.tolist()\n",
    "#catchments_ids = first_half_df.index.tolist()\n",
    "catchments_ids = estreams_attributes_clipped_filters.index.tolist()\n",
    "\n",
    "# Run the iterative function\n",
    "iterative_immediate_downstream = find_iterative_immediate_downstream(df, catchments_ids)\n",
    "\n",
    "# Convert results to a DataFrame for display\n",
    "iterative_downstream_df = pd.DataFrame(iterative_immediate_downstream.items(), \n",
    "                                       columns=['basin_id', 'immediate_downstream_basin'])\n",
    "\n",
    "\n",
    "# Assuming the DataFrame has columns 'basin_id' and 'downstream_id'\n",
    "topology_list = {basin: None for basin in catchments_ids}  # Default to None\n",
    "\n",
    "# Filter DataFrame for relevant basin_ids and update topology\n",
    "for _, row in iterative_downstream_df.iterrows():\n",
    "    if row['basin_id'] in topology_list:\n",
    "        topology_list[row['basin_id']] = row['immediate_downstream_basin']\n",
    "\n",
    "# Generate Nodes dynamically and assign them as global variables\n",
    "catchments = [] # Dictionary to store nodes\n",
    "\n",
    "for cat_id in catchments_ids:\n",
    "    node = Node(\n",
    "        units=[high, general, low],  # Use unit from dictionary or default\n",
    "        weights=perm_areasglobal[cat_id],\n",
    "        area=areas.get(cat_id),  # Use predefined area or default\n",
    "        id=cat_id\n",
    "    )\n",
    "    catchments.append(node)  # Store in the list\n",
    "\n",
    "    # Assign the node as a global variable\n",
    "    globals()[cat_id] = node\n",
    "\n",
    "\n",
    "# Ensure topology only includes nodes that exist in `catchments_ids`\n",
    "topology = {\n",
    "    cat_id: upstream if upstream in catchments_ids else None\n",
    "    for cat_id, upstream in topology_list.items() if cat_id in catchments_ids\n",
    "}\n",
    "\n",
    "# Create the Network\n",
    "model = Network(\n",
    "    nodes=catchments,  # Pass list of Node objects\n",
    "    topology=topology  \n",
    ")\n",
    "\n",
    "model.reset_states()\n",
    "\n",
    "# Set inputs for each node using the manually defined dictionary\n",
    "for cat in catchments:\n",
    "    cat.set_input(inputs[cat.id])  # Correct way to set inputs\n",
    "\n",
    "\n",
    "#best_params_dict['M4_lowersplitter_split-par'] = 0.5\n",
    "\n",
    "\n",
    "model.set_timestep(1.0)\n",
    "model.set_parameters(best_params_dict_model)\n",
    "\n",
    "#hyd_mod.reset_states()\n",
    "output = model.get_output()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2079d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_val_g_1_100 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_val_g_1_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_val_r_1_100 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_val_r_1_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ec7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_g_1_100.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_100.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6415f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "plt.scatter(nse_results_val_r_1_100[\"bfi_obs\"], nse_results_val_r_1_100[\"bfi_sim\"], alpha=0.6)\n",
    "# Set limits (adjust according to your data range)\n",
    "plt.xlim([0.2, 1])\n",
    "plt.ylim([0.2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catchments_ids = second_half_df.index.tolist()\n",
    "#catchments_ids = first_half_df.index.tolist()\n",
    "catchments_ids = estreams_attributes_clipped_filters.index.tolist()\n",
    "\n",
    "# Run the iterative function\n",
    "iterative_immediate_downstream = find_iterative_immediate_downstream(df, catchments_ids)\n",
    "\n",
    "# Convert results to a DataFrame for display\n",
    "iterative_downstream_df = pd.DataFrame(iterative_immediate_downstream.items(), \n",
    "                                       columns=['basin_id', 'immediate_downstream_basin'])\n",
    "\n",
    "\n",
    "# Assuming the DataFrame has columns 'basin_id' and 'downstream_id'\n",
    "topology_list = {basin: None for basin in catchments_ids}  # Default to None\n",
    "\n",
    "# Filter DataFrame for relevant basin_ids and update topology\n",
    "for _, row in iterative_downstream_df.iterrows():\n",
    "    if row['basin_id'] in topology_list:\n",
    "        topology_list[row['basin_id']] = row['immediate_downstream_basin']\n",
    "\n",
    "# Generate Nodes dynamically and assign them as global variables\n",
    "catchments = [] # Dictionary to store nodes\n",
    "\n",
    "for cat_id in catchments_ids:\n",
    "    node = Node(\n",
    "        units=[high, general, low],  # Use unit from dictionary or default\n",
    "        weights=perm_areas[cat_id],\n",
    "        area=areas.get(cat_id),  # Use predefined area or default\n",
    "        id=cat_id\n",
    "    )\n",
    "    catchments.append(node)  # Store in the list\n",
    "\n",
    "    # Assign the node as a global variable\n",
    "    globals()[cat_id] = node\n",
    "\n",
    "\n",
    "# Ensure topology only includes nodes that exist in `catchments_ids`\n",
    "topology = {\n",
    "    cat_id: upstream if upstream in catchments_ids else None\n",
    "    for cat_id, upstream in topology_list.items() if cat_id in catchments_ids\n",
    "}\n",
    "\n",
    "# Create the Network\n",
    "model = Network(\n",
    "    nodes=catchments,  # Pass list of Node objects\n",
    "    topology=topology  \n",
    ")\n",
    "\n",
    "model.reset_states()\n",
    "\n",
    "# Set inputs for each node using the manually defined dictionary\n",
    "for cat in catchments:\n",
    "    cat.set_input(inputs[cat.id])  # Correct way to set inputs\n",
    "\n",
    "\n",
    "#best_params_dict['M4_lowersplitter_split-par'] = 0.5\n",
    "\n",
    "\n",
    "model.set_timestep(1.0)\n",
    "model.set_parameters(best_params_dict_model)\n",
    "\n",
    "#hyd_mod.reset_states()\n",
    "output = model.get_output()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2000-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_val_r_1_100 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_val_r_1_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c3d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_100.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_100.iloc[3:].nse.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b82789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_100.iloc[3:].nse.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce333c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_100[nse_results_val_r_1_100.nse>0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_100.iloc[3:].nse.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159185cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_100[nse_results_val_r_1_100.nse<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45099ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596752c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592f02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2080718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a373845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977b641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62feaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34ecc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2000-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_val_r_1 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_val_r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2000-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "\n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        bfi_sim_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "        bfi_obs_series = np.nan\n",
    "        bfi_sim_series = np.nan\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # Ensure inputs are NumPy arrays\n",
    "        bfi_obs_series = np.array(bfi_obs_series, dtype=np.float64)\n",
    "        bfi_sim_series = np.array(bfi_sim_series, dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        r2_value_bfi = 1 - np.sum((bfi_obs_series - bfi_sim_series) ** 2) / np.sum((bfi_obs_series - np.mean(bfi_obs_series)) ** 2)\n",
    "    except:\n",
    "        r2_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    try:\n",
    "        bfi_obs2 = np.mean(bfi_obs_series)/mean_q_obs\n",
    "        bfi_sim2 = np.mean(bfi_sim_series)/mean_q_calc\n",
    "    except:    \n",
    "        bfi_obs2 = np.nan\n",
    "        bfi_sim2 = np.nan    \n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi,\n",
    "        \"bfi_obs2\": bfi_obs2,\n",
    "        \"bfi_sim2\":bfi_sim2,\n",
    "        \"r2_value_bfi\":r2_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_val_r_1_56 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_val_r_1_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_56.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(nse_results_val_r_1_56[\"bfi_obs2\"], nse_results_val_r_1_56[\"bfi_sim2\"], alpha=0.6)\n",
    "# Set limits (adjust according to your data range)\n",
    "plt.xlim([0.2, 1])\n",
    "plt.ylim([0.2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d533f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2000-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_val_g_1_56 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_val_g_1_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56540de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_cal = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2000-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    \n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    bfi_obs = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    bfi_sim = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=False)\n",
    "    \n",
    "    try:\n",
    "        bfi_obs_series = hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1]\n",
    "        \n",
    "        nse_value_bfi = 1 - obj_fun_nsee(observations=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 0].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 simulation=hydroanalysis.streamflow_signatures.calculate_baseflow_index(Qtimeseries.iloc[365:, 1].values, quality_masks[basin][365:], alpha=0.925, num_filters=3, num_reflect=30, returnBF=True)[1], \n",
    "                                 expo=0.5)\n",
    "    except:\n",
    "        nse_value_bfi = np.nan\n",
    "\n",
    "\n",
    "    nse_results_cal.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc,\n",
    "        \"bfi_obs\": bfi_obs,\n",
    "        \"bfi_sim\":bfi_sim,\n",
    "        \"nse_value_bfi\": nse_value_bfi\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_results_val_g_1 = pd.DataFrame(nse_results_cal)\n",
    "nse_results_val_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1.nse_value_bfi - nse_results_val_g_1.nse_value_bfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_g_1_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6812fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(nse_results_cal_r_1_56.nse - nse_results_cal_g_1_56.nse).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f39f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_r_1_56.nse - nse_results_cal_g_1_56.nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd453a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_r_1_56.nse - nse_results_cal_g_1_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce25f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(nse_results_cal_r_1_56.nse - nse_results_cal_g_1_56.nse).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "(nse_results_val_r_1_56.nse - nse_results_val_g_1_56.nse).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231311f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_r_1_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff = pd.DataFrame(data=nse_results_cal_r_1_56.nse - nse_results_cal_g_1_56.nse)\n",
    "data_diff.index = nse_results_cal_r_1_56.basin\n",
    "data_diff_filtered = data_diff.loc[~data_diff.index.isin(nse_results_cal_g_1.basin.tolist())]\n",
    "data_diff_filtered[\"nse_r1\"] = nse_results_cal_r_1_56.set_index(\"basin\", inplace = False).nse\n",
    "data_diff_filtered[\"nse_g1\"] = nse_results_cal_g_1_56.set_index(\"basin\", inplace = False).nse\n",
    "data_diff_filtered[\"nse_bfi_r1\"] = nse_results_cal_r_1_56.set_index(\"basin\", inplace = False).nse_value_bfi\n",
    "data_diff_filtered[\"nse_bfi_g1\"] = nse_results_cal_g_1_56.set_index(\"basin\", inplace = False).nse_value_bfi\n",
    "\n",
    "data_diff_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff.loc[data_diff.index.isin(nse_results_cal_g_1.basin.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference\n",
    "data_diff = nse_results_cal_r_1_56.nse - nse_results_cal_g_1_56.nse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the bin edges, ensuring a clear separation at zero\n",
    "min_val = -0.5  # Adjust based on your data range\n",
    "max_val = 0.5   # Adjust based on your data range\n",
    "bin_width = 0.01  # Adjust bin width for better separation\n",
    "\n",
    "# Generate bins from min_val to max_val with defined bin width\n",
    "bins = np.arange(min_val, max_val + bin_width, bin_width)\n",
    "\n",
    "# Ensure zero is explicitly included as a bin boundary\n",
    "bins = np.unique(np.append(bins, 0))\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(data_diff, bins=bins, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Difference in NSE Value BFI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of NSE Value BFI Differences\")\n",
    "\n",
    "# Add vertical line at zero for clarity\n",
    "plt.axvline(0, color='red', linestyle='dashed', linewidth=1.5)\n",
    "plt.axvline(-0.05, color='red', linestyle='dashed', linewidth=1.5)\n",
    "plt.axvline(0.05, color='red', linestyle='dashed', linewidth=1.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_filtered[data_diff_filtered.nse_g1>0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_filtered[data_diff_filtered.nse_r1>0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846cce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sort values for cumulative plot\n",
    "nse_values_1 = np.sort(data_diff_filtered[\"nse_bfi_r1\"])\n",
    "nse_values_2 = np.sort(data_diff_filtered[\"nse_bfi_g1\"])\n",
    "\n",
    "# Compute cumulative distribution\n",
    "cumulative_1 = np.linspace(0, 1, len(nse_values_1))\n",
    "cumulative_2 = np.linspace(0, 1, len(nse_values_2))\n",
    "\n",
    "# Plot cumulative distributions\n",
    "plt.plot(nse_values_1, cumulative_1, label=\"Dataset 1 (r_1_101)\", linewidth=2)\n",
    "plt.plot(nse_values_2, cumulative_2, label=\"Dataset 2 (g_1_101)\", linewidth=2)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"NSE Value BFI\")\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"Cumulative Distribution of NSE Value BFI\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sort values for cumulative plot\n",
    "nse_values_1 = np.sort(data_diff_filtered[\"nse_r1\"])\n",
    "nse_values_2 = np.sort(data_diff_filtered[\"nse_g1\"])\n",
    "\n",
    "# Compute cumulative distribution\n",
    "cumulative_1 = np.linspace(0, 1, len(nse_values_1))\n",
    "cumulative_2 = np.linspace(0, 1, len(nse_values_2))\n",
    "\n",
    "# Plot cumulative distributions\n",
    "plt.plot(nse_values_1, cumulative_1, label=\"Dataset 1 (r_1_101)\", linewidth=2)\n",
    "plt.plot(nse_values_2, cumulative_2, label=\"Dataset 2 (g_1_101)\", linewidth=2)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"NSE Value BFI\")\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"Cumulative Distribution of NSE Value BFI\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Compute the difference\n",
    "data_diff = nse_results_cal_r_1_56.nse_value_bfi - nse_results_cal_g_1_56.nse_value_bfi\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the bin edges, ensuring a clear separation at zero\n",
    "min_val = -0.5  # Adjust based on your data range\n",
    "max_val = 0.5   # Adjust based on your data range\n",
    "bin_width = 0.05  # Adjust bin width for better separation\n",
    "\n",
    "# Generate bins from min_val to max_val with defined bin width\n",
    "bins = np.arange(min_val, max_val + bin_width, bin_width)\n",
    "\n",
    "# Ensure zero is explicitly included as a bin boundary\n",
    "bins = np.unique(np.append(bins, 0))\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(data_diff, bins=bins, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Difference in NSE Value BFI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of NSE Value BFI Differences\")\n",
    "\n",
    "# Add vertical line at zero for clarity\n",
    "plt.axvline(0, color='red', linestyle='dashed', linewidth=1.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9547f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1_56.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428030a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_g_1_56.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10fb47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2d607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff = pd.DataFrame(data=nse_results_val_r_1_56.nse - nse_results_val_g_1_56.nse)\n",
    "data_diff.index = nse_results_val_r_1_56.basin\n",
    "data_diff_filtered = data_diff.loc[~data_diff.index.isin(nse_results_val_g_1.basin.tolist())]\n",
    "data_diff_filtered[\"nse_r1\"] = nse_results_val_r_1_56.set_index(\"basin\", inplace = False).nse\n",
    "data_diff_filtered[\"nse_g1\"] = nse_results_val_g_1_56.set_index(\"basin\", inplace = False).nse\n",
    "data_diff_filtered[\"nse_bfi_r1\"] = nse_results_val_r_1_56.set_index(\"basin\", inplace = False).nse_value_bfi\n",
    "data_diff_filtered[\"nse_bfi_g1\"] = nse_results_val_g_1_56.set_index(\"basin\", inplace = False).nse_value_bfi\n",
    "\n",
    "data_diff_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Remove NaN values from the NSE columns before sorting\n",
    "nse_values_1 = np.sort(data_diff_filtered[\"nse_bfi_r1\"].dropna())\n",
    "nse_values_2 = np.sort(data_diff_filtered[\"nse_bfi_g1\"].dropna())\n",
    "\n",
    "# Compute cumulative distribution correctly\n",
    "cumulative_1 = np.arange(1, len(nse_values_1) + 1) / len(nse_values_1)\n",
    "cumulative_2 = np.arange(1, len(nse_values_2) + 1) / len(nse_values_2)\n",
    "\n",
    "# Plot cumulative distributions\n",
    "plt.plot(nse_values_1, cumulative_1, label=\"Dataset 1 (r_1_101)\", linewidth=2)\n",
    "plt.plot(nse_values_2, cumulative_2, label=\"Dataset 2 (g_1_101)\", linewidth=2)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"NSE Value BFI\")\n",
    "plt.xlim(-0.0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"Cumulative Distribution of NSE Value BFI\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Remove NaN values from the NSE columns before sorting\n",
    "nse_values_1 = np.sort(data_diff_filtered[\"nse_r1\"].dropna())\n",
    "nse_values_2 = np.sort(data_diff_filtered[\"nse_g1\"].dropna())\n",
    "\n",
    "# Compute cumulative distribution correctly\n",
    "cumulative_1 = np.arange(1, len(nse_values_1) + 1) / len(nse_values_1)\n",
    "cumulative_2 = np.arange(1, len(nse_values_2) + 1) / len(nse_values_2)\n",
    "\n",
    "# Plot cumulative distributions\n",
    "plt.plot(nse_values_1, cumulative_1, label=\"Dataset 1 (r_1_101)\", linewidth=2)\n",
    "plt.plot(nse_values_2, cumulative_2, label=\"Dataset 2 (g_1_101)\", linewidth=2)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"NSE Value BFI\")\n",
    "plt.xlim(-0.0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"Cumulative Distribution of NSE Value BFI\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3db2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Remove NaN values from the NSE columns before sorting\n",
    "nse_values_1 = np.sort(nse_results_val_r_1_100[\"nse\"].dropna())\n",
    "\n",
    "# Compute cumulative distribution correctly\n",
    "cumulative_1 = np.arange(1, len(nse_values_1) + 1) / len(nse_values_1)\n",
    "\n",
    "# Plot cumulative distributions\n",
    "plt.plot(nse_values_1, cumulative_1, label=\"Dataset 1 (r_1_101)\", linewidth=2)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"NSE Value BFI\")\n",
    "plt.xlim(-0.0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"Cumulative Distribution of NSE Value BFI\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_values_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference\n",
    "data_diff = nse_results_val_r_1_56.nse - nse_results_val_g_1_56.nse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the bin edges, ensuring a clear separation at zero\n",
    "min_val = -0.5  # Adjust based on your data range\n",
    "max_val = 0.5   # Adjust based on your data range\n",
    "bin_width = 0.01  # Adjust bin width for better separation\n",
    "\n",
    "# Generate bins from min_val to max_val with defined bin width\n",
    "bins = np.arange(min_val, max_val + bin_width, bin_width)\n",
    "\n",
    "# Ensure zero is explicitly included as a bin boundary\n",
    "bins = np.unique(np.append(bins, 0))\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(data_diff, bins=bins, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Difference in NSE Value BFI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of NSE Value BFI Differences\")\n",
    "\n",
    "# Add vertical line at zero for clarity\n",
    "plt.axvline(0, color='red', linestyle='dashed', linewidth=1.5)\n",
    "#plt.axvline(-0.05, color='red', linestyle='dashed', linewidth=1.5)\n",
    "#plt.axvline(0.05, color='red', linestyle='dashed', linewidth=1.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef20d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference\n",
    "data_diff = nse_results_val_r_1_56.nse_value_bfi - nse_results_val_g_1_56.nse_value_bfi\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the bin edges, ensuring a clear separation at zero\n",
    "min_val = -0.5  # Adjust based on your data range\n",
    "max_val = 0.5   # Adjust based on your data range\n",
    "bin_width = 0.01  # Adjust bin width for better separation\n",
    "\n",
    "# Generate bins from min_val to max_val with defined bin width\n",
    "bins = np.arange(min_val, max_val + bin_width, bin_width)\n",
    "\n",
    "# Ensure zero is explicitly included as a bin boundary\n",
    "bins = np.unique(np.append(bins, 0))\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(data_diff, bins=bins, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Difference in NSE Value BFI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of NSE Value BFI Differences\")\n",
    "\n",
    "# Add vertical line at zero for clarity\n",
    "plt.axvline(0, color='red', linestyle='dashed', linewidth=1.5)\n",
    "#plt.axvline(-0.05, color='red', linestyle='dashed', linewidth=1.5)\n",
    "#plt.axvline(0.05, color='red', linestyle='dashed', linewidth=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5325401",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_val_r_1.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78efceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2000-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "    \n",
    "    nse_results.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_df_g_1 = pd.DataFrame(nse_results)\n",
    "nse_df_g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2000-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "\n",
    "    nse_results.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_df_r_2 = pd.DataFrame(nse_results)\n",
    "nse_df_r_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('1988-01-01', '2000-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "\n",
    "    nse_results.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_df_r_1 = pd.DataFrame(nse_results)\n",
    "nse_df_r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d7746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb08344",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df_r_1.nse - nse_df_g_1.nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df_r_2.nse - nse_df_g_2.nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_r_2.nse - nse_results_cal_g_2.nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df_r_1.nse - nse_df_g_1.nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c199c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_r_1.nse - nse_results_cal_g_1.nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f1e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e46434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "plt.scatter(nse_df[\"q_mean_obs\"], nse_df[\"q_mean_calc\"], alpha=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d794234",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df_h.nse - nse_df_g.nse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f37228",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_h.nse - nse_results_cal_g.nse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.iloc[365:, 0].values.numpy.nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b77a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_filtered[data_diff_filtered.nse<-0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "estreams_attributes_clipped_filters.columns[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ff320",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_filtered[\"perm_high_regi\"] = estreams_attributes_clipped_filters[\"perm_high_regi\"]\n",
    "data_diff_filtered[\"root_dep_mean\"] = estreams_attributes_clipped_filters[\"root_dep_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a80318",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_filtered[data_diff_filtered.perm_high_regi>70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_filtered[data_diff_filtered.root_dep_mean>110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ba552",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff_filtered.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "estreams_attributes_clipped_filters.loc[data_diff_filtered[data_diff_filtered.nse<-0.05].index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de89cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estreams_attributes_clipped_filters.loc[data_diff_filtered[data_diff_filtered.nse<-0.05].index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d4ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-1988','12-31-2000', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"FR000142\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"FR000142\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"DEBU1959\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"DEBU1959\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-1988','12-31-2000', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"DEBU1959\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"DEBU1959\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.loc[\"2006\":\"2006\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc574a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eedfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80734c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74bfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.loc[\"1996\":\"1996\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.loc[\"1996\":\"1996\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.loc[\"1996\":\"1996\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4206357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.loc[\"1996\":\"1996\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894be7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.loc[\"1996\":\"1996\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_results_cal.nse.plot()\n",
    "nse_df.nse.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aabf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "nse_results_teste = []\n",
    "\n",
    "for basin in catchments_ids:\n",
    "    Qtimeseries = pd.DataFrame(index=pd.date_range('2002-01-01', '2014-12-31', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    nse_value = 1 - obj_fun_nsee(observations=Qtimeseries.iloc[365:, 0].values, \n",
    "                                 simulation=Qtimeseries.iloc[365:, 1].values, \n",
    "                                 expo=0.5)\n",
    "    mean_q_obs = np.nanmean(Qtimeseries.iloc[365:, 0].values)  \n",
    "    mean_q_calc = np.nanmean(Qtimeseries.iloc[365:, 1].values) \n",
    "\n",
    "    nse_results_teste.append({\n",
    "        \"gauge_name\": network_estreams.loc[basin, \"gauge_name\"],\n",
    "        \"basin\": basin,\n",
    "        \"nse\": nse_value,\n",
    "        \"q_mean_obs\": mean_q_obs,\n",
    "        \"q_mean_calc\": mean_q_calc\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "nse_df_teste = pd.DataFrame(nse_results_teste)\n",
    "nse_df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87aec48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00676fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ed4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d19dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e305ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb581e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e4111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin in areas.keys():\n",
    "    Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "    Qtimeseries[\"Qobs\"] = observations[basin]\n",
    "    Qtimeseries[\"Qcalc\"] = output[basin][0]\n",
    "\n",
    "    print(basin, 1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b137ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209deb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70f06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32daeb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-1988','12-31-2000', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"DERP2033\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"DERP2033\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ad88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"FR003237\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"FR003237\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4514546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb9f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bef459",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd640f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"FR003249\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"FR003249\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7735e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"FR003253\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"FR003253\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"LU000007\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"LU000007\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"DEBU1959\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"DEBU1959\"][0]\n",
    "\n",
    "print(1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5))\n",
    "Qtimeseries.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5badd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f847db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950eca8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d9454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1759f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fcd0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb8eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()\n",
    "\n",
    "# Set inputs for each node using the manually defined dictionary\n",
    "for cat in catchments:\n",
    "    cat.set_input(inputs[cat.id])  # Correct way to set inputs\n",
    "\n",
    "\n",
    "best_params_dict['M4_lowersplitter_split-par'] = 0.65\n",
    "\n",
    "\n",
    "model.set_timestep(1.0)\n",
    "model.set_parameters(best_params_dict)\n",
    "\n",
    "#hyd_mod.reset_states()\n",
    "output = model.get_output()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31485cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"FR003253\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"FR003253\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "estreams_attributes.loc[\"FR003253\", \"baseflow_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e23909",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c64996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edff8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"FR003253\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"FR003253\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb0452",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"DERP2007\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"DERP2007\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"LU000007\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"LU000007\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6952a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b058586",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = observations[\"BEWA0107\"]\n",
    "Qtimeseries[\"Qcalc\"] = output[\"BEWA0107\"][0]\n",
    "\n",
    "1 - obj_fun_nsee(observations = Qtimeseries.iloc[365:, 0].values, simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97379ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acf95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dffd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "best_model_run = results[bestindex]                                           # Get the outputs from the best run\n",
    "\n",
    "fields=[word for word in best_model_run.dtype.names if word.startswith('sim')] # Select only the simulated streamflow \n",
    "best_simulation = list(best_model_run[fields])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[bestindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a85cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda45600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d543665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4e1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d44d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112894d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2be274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import spotpy\n",
    "\n",
    "class spotpy_model(object):\n",
    "\n",
    "    def __init__(self, catchments, dt, observations, parameters, parameter_names, output_index, warm_up=365):\n",
    "        \"\"\"\n",
    "        Spotpy model for multi-node calibration in SuperflexPy.\n",
    "\n",
    "        Args:\n",
    "            catchments (list): List of Node objects.\n",
    "            dt (float): Time step.\n",
    "            observations (dict): Observed discharge data for each node.\n",
    "            parameters (list): List of parameter distributions for calibration.\n",
    "            parameter_names (list): Names of the parameters.\n",
    "            output_index (str/int): The output key for extracting model results.\n",
    "            warm_up (int): Number of time steps to ignore in the evaluation.\n",
    "        \"\"\"\n",
    "        self._catchments = catchments  # Use predefined catchments list\n",
    "        self._dt = dt  # Time step\n",
    "\n",
    "        # Store shared calibration parameters\n",
    "        self._parameters = parameters\n",
    "        self._parameter_names = parameter_names\n",
    "\n",
    "        # Store observations for each node\n",
    "        self._observations = observations  # Dictionary {node_id: observed_data}\n",
    "        self._output_index = output_index  # Output key (e.g., 'Q_out')\n",
    "        self._warm_up = int(warm_up)  # Warm-up period\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Generate parameter samples for calibration.\"\"\"\n",
    "        return spotpy.parameter.generate(self._parameters)\n",
    "\n",
    "    def simulation(self, parameters):\n",
    "        \"\"\"Runs the simulation for all nodes using the same parameter set.\"\"\"\n",
    "\n",
    "        # Convert parameter list into a dictionary\n",
    "        named_parameters = {p_name: p for p_name, p in zip(self._parameter_names, parameters)}\n",
    "\n",
    "        outputs = {}  # Store simulation results for each node\n",
    "\n",
    "        for cat in self._catchments:  # Iterate over manually defined catchments\n",
    "            cat.set_parameters(named_parameters)  # Apply shared parameters\n",
    "\n",
    "            # Generate input data\n",
    "            P = np.zeros(100)\n",
    "            P[:10] = np.random.randint(10, size=10)\n",
    "            P[25:30] = np.random.randint(20, size=5)\n",
    "            P[40:60] = np.random.randint(5, size=20)\n",
    "            P[80:83] = np.random.randint(30, 50, size=3)\n",
    "\n",
    "            E = np.ones_like(P) * 2.0  # Constant PET\n",
    "            T = (np.random.rand(100) - 0.2) * 20  # Random Temperature\n",
    "\n",
    "            cat.set_input([P, T, E])  # Directly set input for each node\n",
    "            cat.set_timestep(self._dt)\n",
    "            cat.reset_states()  # Reset internal states\n",
    "\n",
    "            output = cat.get_output()\n",
    "            outputs[cat.id] = output[self._output_index]  # Store results for each node\n",
    "\n",
    "        return outputs  # Dictionary with outputs for each node\n",
    "\n",
    "    def evaluation(self):\n",
    "        \"\"\"Returns the observed data for all nodes.\"\"\"\n",
    "        return self._observations\n",
    "\n",
    "    def objectivefunction(self, simulation, evaluation):\n",
    "        \"\"\"Computes the average NSE (or another metric) across all nodes.\"\"\"\n",
    "\n",
    "        obj_values = []  # Store individual NSE values for each node\n",
    "\n",
    "        for node_id in simulation.keys():\n",
    "            # Apply warm-up period\n",
    "            sim = simulation[node_id][self._warm_up + 1:]\n",
    "            obs = evaluation[node_id][self._warm_up + 1:]\n",
    "\n",
    "            # Compute NSE (or another metric like KGE)\n",
    "            obj_value = obj_fun_nsee(observations=obs, simulation=sim, expo=0.5)\n",
    "            obj_values.append(obj_value)\n",
    "\n",
    "        # Compute the average objective function across all nodes\n",
    "        return np.mean(obj_values)  # Minimize the average error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb7767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04007cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730ef38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ecb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aea552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class spotpy_model(object):\n",
    "\n",
    "    def __init__(self, model, inputs, dt, observations, parameters, parameter_names, output_index, \n",
    "                 warm_up = 365):\n",
    "\n",
    "        self._model = model\n",
    "        self._model.set_input(inputs)\n",
    "        self._model.set_timestep(dt)\n",
    "\n",
    "        self._parameters = parameters\n",
    "        self._parameter_names = parameter_names\n",
    "        self._observarions = observations\n",
    "        self._output_index = output_index\n",
    "        \n",
    "        self._warm_up = int(warm_up)\n",
    "        \n",
    "    def parameters(self):\n",
    "        return spotpy.parameter.generate(self._parameters)\n",
    "    \n",
    "    def simulation(self, parameters):\n",
    "\n",
    "        named_parameters = {}\n",
    "        for p_name, p in zip(self._parameter_names, parameters):\n",
    "            named_parameters[p_name] = p\n",
    "\n",
    "        self._model.set_parameters(named_parameters)\n",
    "        self._model.reset_states()\n",
    "        output = self._model.get_output()\n",
    "\n",
    "        return output[self._output_index]\n",
    "    \n",
    "    def evaluation(self):\n",
    "        return self._observarions\n",
    "    \n",
    "    # Here you can use a pre-defined objective function from spotpy, or you can write down your own:    \n",
    "    def objectivefunction(self, simulation, evaluation):\n",
    "        #obj_fun = spotpy.objectivefunctions.rmse(evaluation=evaluation,\n",
    "        #                                                  simulation=simulation)\n",
    "        #obj_fun = np.sum(np.sqrt(((simulation - evaluation)**2)/100))\n",
    "        #obj_fun = obj_fun_nsee(observations = evaluation, simulation = simulation, expo = 0.5)\n",
    "        \n",
    "        evaluation_used = evaluation[self._warm_up + 1:]\n",
    "        simulation_used = simulation[self._warm_up + 1:]\n",
    "        obj_fun = obj_fun_nsee(observations = evaluation_used, simulation = simulation_used, expo = 0.5)\n",
    "        #obj_fun = obj_fun_kge(observations = evaluation_used, simulation = simulation_used)\n",
    "\n",
    "        \n",
    "        return obj_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DERP2004.reset_states()\n",
    "\n",
    "spotpy_hyd_mod = spotpy_model(\n",
    "    model=DERP2004,\n",
    "    inputs=[P, T, E],\n",
    "    dt=1.0,\n",
    "    observations = Q_obs,\n",
    "    parameters=[\n",
    "        spotpy.parameter.Uniform('M4_fast_k', 1e-5, 1.0), #1e-3, 0.5\n",
    "        #spotpy.parameter.Uniform('M4_fast_alpha', 1.0, 2.0),\n",
    "        spotpy.parameter.Uniform('M4_slow_k ', 1e-8, 0.1), #0.0001, 1.0\n",
    "        #spotpy.parameter.Uniform('M4_slow_alpha ', 1, 2),\n",
    "        #spotpy.parameter.Uniform('M4_unsaturated_Smax', 50, 600), #\n",
    "        \n",
    "        spotpy.parameter.Uniform('M4_unsaturated_Ce', 0.1, 3.0),#0.5, 4.0\n",
    "        spotpy.parameter.Uniform('M4_unsaturated_m', 0.01, 1.0),\n",
    "        spotpy.parameter.Uniform('M4_unsaturated_beta', 0.1, 10.0),#1.0, 4.0\n",
    "        spotpy.parameter.Uniform('M4_lowersplitter_split-par', 0.5, 0.9),\n",
    "        spotpy.parameter.Uniform('M4_lag-fun_lag-time', 1.0, 4.0),\n",
    "        #spotpy.parameter.Uniform('M4_snow_k', 0.0, 1.0),\n",
    "\n",
    "    ],\n",
    "    #parameter_names=['model_FR1_k', 'model_FR1_alpha', 'model_FR1_Ce'],\n",
    "    parameter_names=['M4_fast_k', 'M4_slow_k', 'M4_unsaturated_Ce', 'M4_unsaturated_m', 'M4_unsaturated_beta',\n",
    "                     'M4_lowersplitter_split-par', 'M4_lag-fun_lag-time'], #\"M4_snow_k\"\n",
    "    output_index=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = spotpy.algorithms.sceua(spotpy_hyd_mod, dbname=None, dbformat='ram')\n",
    "sampler.sample(repetitions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sampler.getdata()                                                  # Load the results\n",
    "spotpy.analyser.plot_parametertrace(results)                                 # Show the results\n",
    "\n",
    "\n",
    "bestindex, bestobjf = spotpy.analyser.get_minlikeindex(results)               # Get the best indexes and objective function\n",
    "\n",
    "spotpy.analyser.get_parameters(results)[bestindex]\n",
    "\n",
    "best_params_dict = dict(zip(spotpy.analyser.get_parameternames(results), spotpy.analyser.get_parameters(results)[bestindex]))\n",
    "\n",
    "\n",
    "if 'M4_lowersplitter_splitpar' in best_params_dict:\n",
    "    best_params_dict['M4_lowersplitter_split-par'] = best_params_dict.pop('M4_lowersplitter_splitpar')\n",
    "\n",
    "if 'M4_lagfun_lagtime' in best_params_dict:\n",
    "    best_params_dict['M4_lag-fun_lag-time'] = best_params_dict.pop('M4_lagfun_lagtime')\n",
    "\n",
    "# Remove spaces and replace with underscores (or any other transformation)\n",
    "best_params_dict = {key.replace(\" \", \"\"): value for key, value in best_params_dict.items()}\n",
    "\n",
    "best_model_run = results[bestindex]                                           # Get the outputs from the best run\n",
    "\n",
    "fields=[word for word in best_model_run.dtype.names if word.startswith('sim')] # Select only the simulated streamflow \n",
    "best_simulation = list(best_model_run[fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - obj_fun_nsee(observations = Q_obs[365:], simulation = best_simulation[365:], expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ecb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - obj_fun_kge(observations = Q_obs[365:], simulation = best_simulation[365:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig2, ax2 = plt.subplots(2, 1, figsize=(20, 12), sharex=True)\n",
    "ax2[0].bar(x=np.arange(len(P)), height=P, color='royalblue')\n",
    "ax2[0].set_ylabel('Precipitation [mm/day]')\n",
    "ax2[0].grid(True)\n",
    "ax2[1].plot(np.arange(len(P)), Q_obs, lw=1, color='black', label='Q obs')\n",
    "ax2[1].plot(np.arange(len(P)), best_simulation,'.',  lw=1, color='r', label='Q sim')\n",
    "ax2[1].set_xlabel('Time [days]')\n",
    "ax2[1].set_ylabel('Streamflow [mm/day]')\n",
    "ax2[1].legend()\n",
    "ax2[1].grid(True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_params_dict['M4_lowersplitter_split-par'] = 0.5\n",
    "best_params_dict['M4_fast_k'] = 1.0\n",
    "#best_params_dict['M4_slow_k'] = 0.01\n",
    "#best_params_dict['M4_snow_k'] = 0.01\n",
    "#best_params_dict['M4_lag-fun_lag-time'] = 3.0\n",
    "#best_params_dict['M4_unsaturated_beta'] = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyd_mod.reset_states()\n",
    "hyd_mod.set_input([P,T, E])\n",
    "hyd_mod.set_timestep(1.0)\n",
    "hyd_mod.set_parameters(best_params_dict)\n",
    "\n",
    "#hyd_mod.reset_states()\n",
    "output = hyd_mod.get_output()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-2002','12-31-2014', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = Q_obs\n",
    "Qtimeseries[\"Qcalc\"] = output[0]\n",
    "\n",
    "Qtimeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtimeseries = pd.DataFrame(index = pd.date_range('01-01-1988','12-31-2001', freq='D'))\n",
    "\n",
    "Qtimeseries[\"Qobs\"] = Q_obs\n",
    "Qtimeseries[\"Qcalc\"] = output[0]\n",
    "\n",
    "Qtimeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057497f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comparation = Qtimeseries.copy()\n",
    "\n",
    "data_comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comparation.loc[\"1995-02-01\":\"1995-06-01\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebcda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comparation.loc[\"2005-02-01\":\"2006-06-01\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - obj_fun_nsee(observations = Q_obs[365:], simulation = Qtimeseries.iloc[365:, 1].values, expo = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d156c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams.loc[basin_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737814d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
